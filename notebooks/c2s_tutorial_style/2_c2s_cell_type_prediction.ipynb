{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C2S Tutorial-Style 2: Cell Type Prediction\n",
    "\n",
    "Dieses Notebook ist am Workflow von:\n",
    "- `c2s_tutorial_4_cell_type_prediction.ipynb`\n",
    "\n",
    "Es nutzt das finetunte Modell aus Notebook 1 und evaluiert auf dem Test-Split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional (bei Bedarf):\n",
    "# %pip install -q cell2sentence anndata scanpy datasets transformers pandas numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "import cell2sentence as cs\n",
    "from cell2sentence.tasks import predict_cell_types_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Config ----------\n",
    "# Pfad zu run_info.json aus Notebook 1 eintragen\n",
    "RUN_INFO_PATH = Path('./runs/REPLACE_WITH_YOUR_RUN/run_info.json')\n",
    "\n",
    "assert RUN_INFO_PATH.exists(), (\n",
    "    'Bitte zuerst Notebook 1 ausfÃ¼hren und RUN_INFO_PATH auf dessen run_info.json setzen.'\n",
    ")\n",
    "\n",
    "with RUN_INFO_PATH.open() as f:\n",
    "    run_info = json.load(f)\n",
    "\n",
    "H5AD_PATH = Path(run_info['h5ad_path'])\n",
    "FINETUNED_MODEL_PATH = Path(run_info['finetuned_model_path'])\n",
    "SPLIT_PATH = Path(run_info['split_indices_path'])\n",
    "TOP_K_GENES = int(run_info.get('top_k_genes', 200))\n",
    "\n",
    "assert H5AD_PATH.exists(), f'Not found: {H5AD_PATH}'\n",
    "assert FINETUNED_MODEL_PATH.exists(), f'Not found: {FINETUNED_MODEL_PATH}'\n",
    "assert SPLIT_PATH.exists(), f'Not found: {SPLIT_PATH}'\n",
    "\n",
    "PRED_DIR = RUN_INFO_PATH.parent / 'predictions'\n",
    "PRED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('using finetuned model:', FINETUNED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load split indices ----------\n",
    "with SPLIT_PATH.open() as f:\n",
    "    split_indices = json.load(f)\n",
    "\n",
    "print({k: len(v) for k, v in split_indices.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Build CSData from the same dataset ----------\n",
    "adata = ad.read_h5ad(H5AD_PATH)\n",
    "adata.var_names_make_unique()\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "label_cols = [c for c in ['cell_type', 'tissue', 'batch_condition', 'organism', 'sex'] if c in adata.obs.columns]\n",
    "arrow_ds, vocab = cs.CSData.adata_to_arrow(\n",
    "    adata,\n",
    "    random_state=42,\n",
    "    sentence_delimiter=' ',\n",
    "    label_col_names=label_cols,\n",
    ")\n",
    "\n",
    "test_ids = split_indices.get('test', [])\n",
    "if len(test_ids) == 0:\n",
    "    raise ValueError('No test split found in split_indices.json')\n",
    "\n",
    "test_arrow = arrow_ds.select(test_ids)\n",
    "\n",
    "csdata_test = cs.CSData.csdata_from_arrow(\n",
    "    arrow_dataset=test_arrow,\n",
    "    vocabulary=vocab,\n",
    "    save_dir=str(PRED_DIR),\n",
    "    save_name='test_subset_arrow',\n",
    "    dataset_backend='arrow',\n",
    ")\n",
    "\n",
    "print('test samples:', len(test_arrow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load finetuned model ----------\n",
    "csmodel = cs.CSModel(\n",
    "    model_name_or_path=str(FINETUNED_MODEL_PATH),\n",
    "    save_dir=str(PRED_DIR / 'model_wrapper'),\n",
    "    save_name='prediction_wrapper',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Cell type prediction ----------\n",
    "preds = predict_cell_types_of_data(\n",
    "    csdata=csdata_test,\n",
    "    csmodel=csmodel,\n",
    "    n_genes=TOP_K_GENES,\n",
    "    max_num_tokens=32,\n",
    ")\n",
    "\n",
    "y_true = [test_arrow[i]['cell_type'] for i in range(len(test_arrow))]\n",
    "y_pred = [str(p).strip() for p in preds]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y_true': y_true,\n",
    "    'y_pred': y_pred,\n",
    "})\n",
    "df['exact_match'] = (df['y_true'] == df['y_pred']).astype(int)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Normalized exact match (more robust) ----------\n",
    "def normalize_label(x: str) -> str:\n",
    "    x = x.lower().strip()\n",
    "    x = x.translate(str.maketrans('', '', string.punctuation))\n",
    "    x = ' '.join(x.split())\n",
    "    return x\n",
    "\n",
    "df['y_true_norm'] = df['y_true'].map(normalize_label)\n",
    "df['y_pred_norm'] = df['y_pred'].map(normalize_label)\n",
    "df['exact_match_norm'] = (df['y_true_norm'] == df['y_pred_norm']).astype(int)\n",
    "\n",
    "print('Exact match       :', round(df['exact_match'].mean(), 4))\n",
    "print('Exact match (norm):', round(df['exact_match_norm'].mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Save predictions ----------\n",
    "pred_csv = PRED_DIR / 'cell_type_predictions_test.csv'\n",
    "df.to_csv(pred_csv, index=False)\n",
    "print('saved:', pred_csv.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
