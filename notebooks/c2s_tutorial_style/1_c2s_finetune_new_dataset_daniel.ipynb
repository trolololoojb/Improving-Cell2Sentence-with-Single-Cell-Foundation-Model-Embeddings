{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C2S Tutorial-Style 1: Finetuning On New Dataset\n",
    "\n",
    "Dieses Notebook ist am Workflow von:\n",
    "- `c2s_tutorial_3_finetuning_on_new_datasets.ipynb`\n",
    "\n",
    "Ziel: `vandijklab/C2S-Pythia-410m-cell-type-prediction` auf deinem Datensatz feinjustieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24ff4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional (bei Bedarf):\n",
    "# %pip install -q cell2sentence anndata scanpy transformers datasets pandas numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a636ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python built-in libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import random\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    import torch\n",
    "except RuntimeError as e:\n",
    "    _msg = str(e)\n",
    "    if ('RpcBackendOptions' in _msg) or ('already has a docstring' in _msg):\n",
    "        raise RuntimeError(\n",
    "            'Torch is in a partially initialized state in this kernel. '\n",
    "            'Restart the Jupyter kernel, then run the notebook from the first cell.'\n",
    "        ) from e\n",
    "    raise\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from transformers.utils import logging as hf_logging\n",
    "hf_logging.enable_progress_bar()\n",
    "\n",
    "# Single-cell libraries\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "\n",
    "# Cell2Sentence imports\n",
    "import cell2sentence as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4bdd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_DIR: /root/AI-Biomedicine/Improving-Cell2Sentence-with-Single-Cell-Foundation-Model-Embeddings/notebooks/c2s_tutorial_style/runs/2026-02-26_16-39-38\n"
     ]
    }
   ],
   "source": [
    "# ---------- Config ----------\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = Path('../../data/dominguez_conde_immune_tissue_two_donors.h5ad')\n",
    "BASE_MODEL = 'vandijklab/C2S-Pythia-410m-cell-type-prediction'\n",
    "TRAINING_TASK = 'cell_type_prediction'\n",
    "TOP_K_GENES = 200\n",
    "\n",
    "RUN_NAME = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "RUN_DIR = Path('./runs') / RUN_NAME\n",
    "CSDATA_DIR = RUN_DIR / 'csdata'\n",
    "MODEL_DIR = RUN_DIR / 'model'\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CSDATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert DATA_PATH.exists(), f'Not found: {DATA_PATH.resolve()}'\n",
    "print('RUN_DIR:', RUN_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e800fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (29773, 36503)\n",
      "obs columns: ['cell_type', 'tissue', 'batch_condition', 'organism', 'assay', 'sex']\n"
     ]
    }
   ],
   "source": [
    "# ---------- Load dataset ----------\n",
    "adata = anndata.read_h5ad(DATA_PATH)\n",
    "print('shape:', adata.shape)\n",
    "print('obs columns:', list(adata.obs.columns))\n",
    "\n",
    "if 'cell_type' not in adata.obs.columns:\n",
    "    raise ValueError(\"adata.obs must contain 'cell_type' for training labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce6249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Minimal preprocessing (tutorial-style baseline) ----------\n",
    "adata = adata.copy()\n",
    "# adata.var_names_make_unique()\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata, base=10)\n",
    "\n",
    "# label_cols = [c for c in ['cell_type', 'tissue', 'batch_condition', 'organism', 'sex'] if c in adata.obs.columns]\n",
    "\n",
    "adata_obs_cols_to_keep = [\"cell_type\", \"tissue\", \"batch_condition\", \"organism\", \"sex\"]\n",
    "# print('label columns:', label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8893ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29773/29773 [00:10<00:00, 2776.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples in arrow: 29773\n",
      "vocab size: 23944\n"
     ]
    }
   ],
   "source": [
    "# ---------- AnnData -> Arrow + vocabulary ----------\n",
    "arrow_ds, vocab = cs.CSData.adata_to_arrow(\n",
    "    adata,\n",
    "    random_state=SEED,\n",
    "    sentence_delimiter=' ',\n",
    "    label_col_names=adata_obs_cols_to_keep,\n",
    ")\n",
    "print('n samples in arrow:', len(arrow_ds))\n",
    "print('vocab size:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "746b6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------- Train/val/test split ----------\n",
    "# _, split_indices = cs.utils.train_test_split_arrow_ds(arrow_ds)\n",
    "\n",
    "# split_path = RUN_DIR / 'split_indices.json'\n",
    "# with split_path.open('w') as f:\n",
    "#     json.dump(split_indices, f, indent=2)\n",
    "\n",
    "# print('saved:', split_path.resolve())\n",
    "# print({k: len(v) for k, v in split_indices.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a711ce98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e2b4c3c33a4d46b8f7c835adcd65e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/29773 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSData Object; Path=runs/2026-02-26_16-39-38/csdata/dataset_arrow, Format=arrow\n"
     ]
    }
   ],
   "source": [
    "# ---------- Save CSData ----------\n",
    "csdata = cs.CSData.csdata_from_arrow(\n",
    "    arrow_dataset=arrow_ds,\n",
    "    vocabulary=vocab,\n",
    "    save_dir=str(CSDATA_DIR),\n",
    "    save_name='dataset_arrow',\n",
    "    dataset_backend='arrow',\n",
    ")\n",
    "print(csdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04726f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f19621fc8aa4c1c9c8dc64e2c267f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/899 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531a1d9f3d4b4a9cbd5c6f35222c2c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885ece1a6de54f699cbb793122270499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: CSModel Object; Path=runs/2026-02-26_16-39-38/model/finetuned_cell_type_prediction\n"
     ]
    }
   ],
   "source": [
    "# ---------- Init model ----------\n",
    "csmodel = cs.CSModel(\n",
    "    model_name_or_path=BASE_MODEL,\n",
    "    save_dir=str(MODEL_DIR),\n",
    "    save_name='finetuned_cell_type_prediction',\n",
    ")\n",
    "print('model:', csmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b896f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=0,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=True,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=False,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=50,\n",
       "eval_strategy=IntervalStrategy.STEPS,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=None,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=4,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=False,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=1e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=runs/2026-02-26_16-39-38/model/hf_trainer_output/runs/Feb26_16-40-42_trolololoo,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=1,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.COSINE,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=loss,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=5,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=runs/2026-02-26_16-39-38/model/hf_trainer_output,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=runs/2026-02-26_16-39-38/model/hf_trainer_output,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=100,\n",
       "save_strategy=IntervalStrategy.STEPS,\n",
       "save_total_limit=2,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=True,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=1,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ---------- TrainingArguments ----------\n",
    "HF_OUTPUT_DIR = MODEL_DIR / 'hf_trainer_output'\n",
    "HF_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=str(HF_OUTPUT_DIR),\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=5,\n",
    "    warmup_steps=1,\n",
    "    lr_scheduler_type='cosine',\n",
    "    logging_steps=1, # loggevery 50 steps (not epochs) to get more frequent feedback on training progress, especially since the dataset is small and we want to see multiple evals within an epoch\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=50,\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none',\n",
    "    use_cpu=True\n",
    ")\n",
    "train_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795f3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training heartbeat every 1 steps.\n",
      "Reloading model from path on disk: runs/2026-02-26_16-39-38/model/finetuned_cell_type_prediction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e22f4e866684101aba930eafcc1497f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29773 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training. Output directory: runs/2026-02-26_16-39-38/model/hf_trainer_output\n",
      "Selecting 10 samples of eval dataset to shorten validation loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/AI-Biomedicine/Improving-Cell2Sentence-with-Single-Cell-Foundation-Model-Embeddings/.venv/lib/python3.13/site-packages/transformers/trainer.py:3543: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Fine-tune ----------\n",
    "# Compatibility shim for newer transformers versions where Trainer uses\n",
    "# `processing_class` instead of `tokenizer`.\n",
    "import inspect\n",
    "from transformers import Trainer\n",
    "\n",
    "_trainer_sig = inspect.signature(Trainer.__init__).parameters\n",
    "if ('processing_class' in _trainer_sig) and ('tokenizer' not in _trainer_sig):\n",
    "    _orig_trainer_init = Trainer.__init__\n",
    "    def _trainer_init_compat(self, *args, **kwargs):\n",
    "        if 'tokenizer' in kwargs and 'processing_class' not in kwargs:\n",
    "            kwargs['processing_class'] = kwargs.pop('tokenizer')\n",
    "        return _orig_trainer_init(self, *args, **kwargs)\n",
    "    Trainer.__init__ = _trainer_init_compat\n",
    "\n",
    "# Prefer periodic text logs over tqdm progress bars\n",
    "if hasattr(train_args, 'disable_tqdm'):\n",
    "    train_args.disable_tqdm = True\n",
    "if hasattr(train_args, 'logging_strategy'):\n",
    "    train_args.logging_strategy = 'steps'\n",
    "if hasattr(train_args, 'logging_steps'):\n",
    "    train_args.logging_steps = max(1, int(getattr(train_args, 'logging_steps', 50) or 50))\n",
    "if hasattr(train_args, 'report_to'):\n",
    "    train_args.report_to = []\n",
    "print(f\"Training heartbeat every {getattr(train_args, 'logging_steps', 'N/A')} steps.\")\n",
    "\n",
    "csmodel.fine_tune(\n",
    "    csdata=csdata,\n",
    "    task=TRAINING_TASK,\n",
    "    train_args=train_args,\n",
    "    loss_on_response_only=False,\n",
    "    top_k_genes=TOP_K_GENES,\n",
    "    max_eval_samples=10, \n",
    "    num_proc=1,\n",
    "    # data_split_indices_dict={\n",
    "    #     'train': split_indices['train'],\n",
    "    #     'val': split_indices['val'],\n",
    "    #     'test': split_indices.get('test', []),\n",
    "    # },\n",
    ")\n",
    "print('Fine-tuning finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Save run metadata for Notebook 2 ----------\n",
    "run_info = {\n",
    "    'h5ad_path': str(DATA_PATH),\n",
    "    'base_model': BASE_MODEL,\n",
    "    'training_task': TRAINING_TASK,\n",
    "    'top_k_genes': TOP_K_GENES,\n",
    "    'run_dir': str(RUN_DIR.resolve()),\n",
    "    'csdata_dir': str(CSDATA_DIR.resolve()),\n",
    "    'model_dir': str(MODEL_DIR.resolve()),\n",
    "    'finetuned_model_path': str((MODEL_DIR / 'finetuned_cell_type_prediction').resolve()),\n",
    "    # 'split_indices_path': str(split_path.resolve()),\n",
    "}\n",
    "\n",
    "run_info_path = RUN_DIR / 'run_info.json'\n",
    "with run_info_path.open('w') as f:\n",
    "    json.dump(run_info, f, indent=2)\n",
    "\n",
    "print('saved:', run_info_path.resolve())\n",
    "run_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
