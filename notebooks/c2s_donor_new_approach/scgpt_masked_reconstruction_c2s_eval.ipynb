{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# scGPT Gene Masking → Reconstruction → C2S Cell-Type Evaluation\n",
    "\n",
    "**Pipeline:**\n",
    "1. Load 24 donor cells (same sample as `c2s_donor_celltype_prediction.ipynb`)\n",
    "2. **Mask** – randomly zero out `MASK_FRACTION` of each cell's expressed genes\n",
    "3. **Reconstruct** – feed masked cells through `tdc/scGPT` (with `-1` mask tokens)\n",
    "   and replace masked positions with scGPT's predicted expression values\n",
    "4. **Evaluate** – run C2S cell-type prediction on three AnnData objects:\n",
    "   - `original` (clean baseline)\n",
    "   - `masked`   (corrupted, masked genes → 0)\n",
    "   - `reconstructed` (scGPT-repaired)\n",
    "5. **Compare** results side-by-side using the 3-tier accuracy metric\n",
    "   (Exactly correct / Partly correct / Not correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install dependencies\n",
    "# %pip install -q cell2sentence anndata scanpy datasets transformers pandas numpy scipy PyTDC torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\c2s_wsl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import torch\n",
    "\n",
    "import cell2sentence as cs\n",
    "from cell2sentence.tasks import predict_cell_types_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ── Configuration ─────────────────────────────────────────────────────────────\n",
    "SEED          = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "H5AD_PATH     = Path('../../data/dominguez_conde_immune_tissue_two_donors.h5ad')\n",
    "DONOR_COLUMN  = 'batch_condition'\n",
    "DONOR_VALUE   = 'A29'\n",
    "N_CELLS       = 24\n",
    "TOP_K_GENES   = 200          # genes passed to C2S\n",
    "MASK_FRACTION = 0.40         # fraction of expressed genes to mask per cell\n",
    "MASK_VALUE    = -1.0         # scGPT sentinel for masked positions (must be != 0)\n",
    "C2S_MODEL     = 'vandijklab/C2S-Pythia-410m-cell-type-prediction'\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', DEVICE)\n",
    "\n",
    "assert H5AD_PATH.exists(), f'File not found: {H5AD_PATH.resolve()}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section1",
   "metadata": {},
   "source": [
    "## 1 · Load data & sample 24 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (29773, 36503)\n",
      "Donor A29: 17327 cells  →  sampled 24\n",
      "cell_type\n",
      "macrophage                                               4\n",
      "memory B cell                                            3\n",
      "naive thymus-derived CD4-positive, alpha-beta T cell     3\n",
      "T follicular helper cell                                 2\n",
      "classical monocyte                                       2\n",
      "plasma cell                                              2\n",
      "CD4-positive helper T cell                               1\n",
      "CD16-negative, CD56-bright natural killer cell, human    1\n",
      "alveolar macrophage                                      1\n",
      "effector memory CD4-positive, alpha-beta T cell          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "adata = ad.read_h5ad(H5AD_PATH)\n",
    "print('Full dataset shape:', adata.shape)\n",
    "\n",
    "adata_donor = adata[adata.obs[DONOR_COLUMN] == DONOR_VALUE].copy()\n",
    "rng = np.random.default_rng(SEED)\n",
    "idx = rng.choice(adata_donor.n_obs, size=N_CELLS, replace=False)\n",
    "adata_small = adata_donor[idx].copy()\n",
    "\n",
    "print(f'Donor {DONOR_VALUE}: {adata_donor.n_obs} cells  →  sampled {adata_small.n_obs}')\n",
    "print(adata_small.obs['cell_type'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section2",
   "metadata": {},
   "source": [
    "## 2 · Preprocessing (normalize + log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-preprocess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression matrix: (24, 36503)\n",
      "Sparsity: 95.3% zeros per cell on average\n"
     ]
    }
   ],
   "source": [
    "adata_small.var_names_make_unique()\n",
    "sc.pp.normalize_total(adata_small, target_sum=1e4)\n",
    "sc.pp.log1p(adata_small)\n",
    "\n",
    "# Dense expression matrix  (n_cells × n_genes)\n",
    "import scipy.sparse as sp\n",
    "X_orig = adata_small.X.toarray() if sp.issparse(adata_small.X) else adata_small.X.copy()\n",
    "gene_names = np.array(adata_small.var_names.tolist())\n",
    "\n",
    "print('Expression matrix:', X_orig.shape)\n",
    "print(f'Sparsity: {(X_orig == 0).mean()*100:.1f}% zeros per cell on average')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section3",
   "metadata": {},
   "source": [
    "## 3 · Random gene masking\n",
    "\n",
    "For each cell, `MASK_FRACTION` of the expressed (non-zero) genes are set to  \n",
    "`MASK_VALUE = -1` internally. A separate zero-copy is created for C2S  \n",
    "(since C2S expects non-negative expression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-mask",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked 16337 genes across 24 cells (~681 per cell, 40% of expressed)\n"
     ]
    }
   ],
   "source": [
    "# X_scgpt_in : expression matrix sent to scGPT  (masked genes = -1, kept in tokenizer)\n",
    "# X_masked   : expression matrix for C2S masked baseline  (masked genes = 0)\n",
    "# mask_record: list of boolean arrays tracking which gene positions were masked\n",
    "\n",
    "rng_mask = np.random.default_rng(SEED)\n",
    "\n",
    "X_scgpt_in = X_orig.copy()\n",
    "X_masked   = X_orig.copy()\n",
    "mask_record = []          # mask_record[i] -> indices of masked genes in cell i\n",
    "\n",
    "total_masked = 0\n",
    "for i in range(X_orig.shape[0]):\n",
    "    expressed_idx = np.where(X_orig[i] > 0)[0]\n",
    "    n_mask = max(1, int(len(expressed_idx) * MASK_FRACTION))\n",
    "    masked_idx = rng_mask.choice(expressed_idx, size=n_mask, replace=False)\n",
    "\n",
    "    X_scgpt_in[i, masked_idx] = MASK_VALUE  # -1  → tokenizer keeps these\n",
    "    X_masked[i, masked_idx]   = 0.0         # 0   → removed from C2S\n",
    "\n",
    "    mask_record.append(masked_idx)\n",
    "    total_masked += n_mask\n",
    "\n",
    "print(f'Masked {total_masked} genes across {N_CELLS} cells'\n",
    "      f' (~{total_masked/N_CELLS:.0f} per cell, {MASK_FRACTION*100:.0f}% of expressed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section4",
   "metadata": {},
   "source": [
    "\n",
    "## 4 · scGPT reconstruction  *(no TDC – native scgpt package)*\n",
    "\n",
    "We load the model via `huggingface_hub.snapshot_download` and the native\n",
    "`scgpt.model.TransformerModel` + `scgpt.tokenizer.GeneVocab`.\n",
    "\n",
    "**Masking strategy:** masked genes are set to `-1` (scGPT's standard mask sentinel).\n",
    "Since `-1 ≠ 0`, they stay in the gene sequence passed to the model.  \n",
    "`mlm_output` predicts expression at **every position** – including the `-1` ones.  \n",
    "Those predicted values replace the masked genes in `X_reconstructed`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-scgpt-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "from scgpt.model import TransformerModel\n",
    "from scgpt.tokenizer import GeneVocab\n",
    "\n",
    "# ── Download weights from HuggingFace ────────────────────────────────────────\n",
    "SCGPT_HF   = 'tdc/scGPT'          # change to 'bowang-lab/scGPT_human' if needed\n",
    "SCGPT_DIR  = Path('./scgpt_checkpoint')\n",
    "\n",
    "print(f'Downloading {SCGPT_HF} from HuggingFace …')\n",
    "local_dir = snapshot_download(SCGPT_HF, local_dir=str(SCGPT_DIR))\n",
    "local_dir  = Path(local_dir)\n",
    "print('Files:', [f.name for f in local_dir.iterdir()])\n",
    "\n",
    "# ── Vocabulary ────────────────────────────────────────────────────────────────\n",
    "vocab_path = local_dir / 'vocab.json'\n",
    "assert vocab_path.exists(), f'vocab.json not found in {local_dir}'\n",
    "vocab  = GeneVocab.from_file(str(vocab_path))\n",
    "PAD_ID = vocab['<pad>'] if '<pad>' in vocab else 0\n",
    "UNK_ID = vocab['<unk>'] if '<unk>' in vocab else PAD_ID\n",
    "print(f'Vocabulary size: {len(vocab)}  |  PAD={PAD_ID}  UNK={UNK_ID}')\n",
    "\n",
    "# ── Model config ──────────────────────────────────────────────────────────────\n",
    "config_path = local_dir / 'args.json'   # scGPT saves as args.json\n",
    "if not config_path.exists():\n",
    "    config_path = local_dir / 'config.json'\n",
    "with open(config_path) as f:\n",
    "    cfg = json.load(f)\n",
    "print('Config keys:', list(cfg.keys())[:10])\n",
    "\n",
    "# ── Build model architecture ──────────────────────────────────────────────────\n",
    "scgpt_model = TransformerModel(\n",
    "    ntoken          = len(vocab),\n",
    "    d_model         = cfg.get('embsize',     cfg.get('d_model',  512)),\n",
    "    nhead           = cfg.get('nheads',      cfg.get('nhead',      8)),\n",
    "    d_hid           = cfg.get('d_hid',       cfg.get('d_hid',    512)),\n",
    "    nlayers         = cfg.get('nlayers',     12),\n",
    "    nlayers_cls     = cfg.get('nlayers_cls', 3),\n",
    "    n_cls           = 1,          # not used at inference\n",
    "    dropout         = 0.0,\n",
    "    pad_token       = '<pad>',\n",
    "    pad_value       = PAD_ID,\n",
    "    do_mvc          = cfg.get('GEPC',        cfg.get('do_mvc',  False)),\n",
    "    do_dab          = cfg.get('do_dab',      False),\n",
    "    use_batch_labels= cfg.get('use_batch_labels', False),\n",
    "    num_batch_labels= cfg.get('num_batch_labels', 1),\n",
    "    domain_spec_batchnorm = cfg.get('dsbn', False),\n",
    "    input_emb_style = cfg.get('input_emb_style', 'continuous'),\n",
    "    n_input_bins    = cfg.get('n_input_bins', 51),\n",
    "    explicit_zero_prob = cfg.get('explicit_zero_prob', False),\n",
    "    use_fast_transformer = False,   # disable flash-attn (not needed on CPU)\n",
    "    pre_norm        = cfg.get('pre_norm', False),\n",
    ")\n",
    "\n",
    "# ── Load weights ──────────────────────────────────────────────────────────────\n",
    "ckpt_path = local_dir / 'best_model.pt'\n",
    "if not ckpt_path.exists():\n",
    "    ckpt_path = local_dir / 'model.pt'\n",
    "assert ckpt_path.exists(), f'No model weights found in {local_dir}'\n",
    "\n",
    "state = torch.load(ckpt_path, map_location='cpu')\n",
    "if isinstance(state, dict) and 'model_state_dict' in state:\n",
    "    state = state['model_state_dict']\n",
    "missing, unexpected = scgpt_model.load_state_dict(state, strict=False)\n",
    "if missing:\n",
    "    print(f'Missing keys ({len(missing)}): {missing[:5]} …')\n",
    "if unexpected:\n",
    "    print(f'Unexpected keys ({len(unexpected)}): {unexpected[:5]} …')\n",
    "\n",
    "scgpt_model = scgpt_model.to(DEVICE)\n",
    "scgpt_model.eval()\n",
    "print(f'\\nscGPT ready on {DEVICE}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-scgpt-reconstruct",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def gene_names_to_ids(names):\n",
    "    \"\"\"Map gene name strings → scGPT vocabulary IDs (UNK_ID for out-of-vocab genes).\"\"\"\n",
    "    return np.array([vocab[g] if g in vocab else UNK_ID for g in names], dtype=np.int64)\n",
    "\n",
    "# X_reconstructed: copy of original; masked gene positions will be overwritten\n",
    "X_reconstructed = X_orig.copy()\n",
    "n_in_vocab  = 0\n",
    "n_recovered = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(N_CELLS), desc='scGPT reconstruction'):\n",
    "\n",
    "        cell_expr = X_scgpt_in[i]          # shape (n_genes,); -1 for masked genes\n",
    "\n",
    "        # ── Select non-zero genes (includes -1 masked ones) ──────────────────\n",
    "        nonzero_idx = np.where(cell_expr != 0)[0]\n",
    "        if len(nonzero_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        genes_sel  = gene_names[nonzero_idx]                    # gene name strings\n",
    "        vals_sel   = cell_expr[nonzero_idx].astype(np.float32)  # expr values (incl. -1)\n",
    "        gene_ids   = gene_names_to_ids(genes_sel)               # vocab IDs\n",
    "\n",
    "        # ── Build tensors ─────────────────────────────────────────────────────\n",
    "        src_t   = torch.from_numpy(gene_ids).unsqueeze(0).to(DEVICE)    # (1, L)\n",
    "        vals_t  = torch.from_numpy(vals_sel).unsqueeze(0).to(DEVICE)    # (1, L)\n",
    "        # padding mask: False = attend, True = ignore  (no padding here)\n",
    "        pad_mask = torch.zeros(1, len(gene_ids), dtype=torch.bool, device=DEVICE)\n",
    "\n",
    "        n_in_vocab += int((gene_ids != UNK_ID).sum())\n",
    "\n",
    "        # ── scGPT forward pass ────────────────────────────────────────────────\n",
    "        # mlm_output has shape (1, L) or (1, L, 1) – predicts expression at\n",
    "        # every position, including the masked (-1) ones.\n",
    "        out = scgpt_model(\n",
    "            src                  = src_t,\n",
    "            values               = vals_t,\n",
    "            src_key_padding_mask = pad_mask,\n",
    "            CLS                  = False,\n",
    "            output_hidden_states = False,\n",
    "        )\n",
    "\n",
    "        mlm = out.get('mlm_output')\n",
    "        if mlm is None:\n",
    "            print(f'  Cell {i}: mlm_output not in scGPT output '\n",
    "                  f'(keys: {list(out.keys())}) – skipping')\n",
    "            continue\n",
    "\n",
    "        if mlm.ndim == 3:\n",
    "            mlm = mlm.squeeze(-1)           # (1, L, 1) → (1, L)\n",
    "        mlm_np = mlm.squeeze(0).cpu().float().numpy()   # (L,)\n",
    "\n",
    "        # ── Find masked positions and fill with scGPT predictions ─────────────\n",
    "        masked_in_local = np.where(vals_sel < 0)[0]    # positions where value was -1\n",
    "        if len(masked_in_local) == 0:\n",
    "            continue\n",
    "\n",
    "        masked_orig_idx = nonzero_idx[masked_in_local]  # back to global gene indices\n",
    "        predicted_vals  = np.clip(mlm_np[masked_in_local], 0.0, None)\n",
    "\n",
    "        X_reconstructed[i, masked_orig_idx] = predicted_vals\n",
    "        n_recovered += len(masked_orig_idx)\n",
    "\n",
    "print(f'\\nReconstruction complete.')\n",
    "print(f'  Avg genes in scGPT vocab / cell : {n_in_vocab / N_CELLS:.0f}')\n",
    "print(f'  Masked genes recovered          : {n_recovered} / {total_masked}'\n",
    "      f'  ({n_recovered / total_masked * 100:.1f} %)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section5",
   "metadata": {},
   "source": [
    "## 5 · Build three AnnData objects\n",
    "\n",
    "| Name | Expression matrix | Description |\n",
    "|---|---|---|\n",
    "| `adata_original` | `X_orig` | Clean, unmodified cells |\n",
    "| `adata_masked` | `X_masked` | Corrupted: `MASK_FRACTION` genes zeroed |\n",
    "| `adata_reconstructed` | `X_reconstructed` | scGPT-repaired: masked genes filled with predicted expression |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-build-adatas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "def make_adata(X_new, template_adata):\n",
    "    \"\"\"Clone the obs/var metadata from template and replace the expression matrix.\"\"\"\n",
    "    a = ad.AnnData(\n",
    "        X=sp.csr_matrix(X_new),\n",
    "        obs=template_adata.obs.copy(),\n",
    "        var=template_adata.var.copy(),\n",
    "    )\n",
    "    return a\n",
    "\n",
    "adata_original     = make_adata(X_orig,         adata_small)\n",
    "adata_masked       = make_adata(X_masked,        adata_small)\n",
    "adata_reconstructed = make_adata(X_reconstructed, adata_small)\n",
    "\n",
    "print('AnnData objects created:')\n",
    "for name, a in [('original', adata_original), ('masked', adata_masked), ('reconstructed', adata_reconstructed)]:\n",
    "    mean_nonzero = (a.X.toarray() > 0).mean()\n",
    "    print(f'  {name:15s}  non-zero fraction: {mean_nonzero:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section6",
   "metadata": {},
   "source": [
    "## 6 · C2S Cell-Type Prediction (3×)\n",
    "\n",
    "> **Runtime note:** each C2S call takes ~9 min on CPU (22 s/cell × 24 cells).  \n",
    "> Total ≈ 27 min. Grab a coffee ☕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-c2s-helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [c for c in ['cell_type', DONOR_COLUMN, 'tissue', 'sex', 'organism']\n",
    "              if c in adata_small.obs.columns]\n",
    "\n",
    "# Load C2S model once (we'll reuse it across all three predictions)\n",
    "csmodel = cs.CSModel(\n",
    "    model_name_or_path=C2S_MODEL,\n",
    "    save_dir='./tmp_c2s_reconstruction_model',\n",
    "    save_name='pretrained_c2s_inference',\n",
    ")\n",
    "print('C2S model loaded:', C2S_MODEL)\n",
    "\n",
    "\n",
    "def run_c2s(adata_in, tag, csmodel_in):\n",
    "    \"\"\"Run C2S cell-type prediction and return a DataFrame with y_true / y_pred.\"\"\"\n",
    "    print(f'\\n─── C2S: {tag} ───')\n",
    "    arrow_ds, vocab = cs.CSData.adata_to_arrow(\n",
    "        adata_in,\n",
    "        random_state=SEED,\n",
    "        sentence_delimiter=' ',\n",
    "        label_col_names=label_cols,\n",
    "    )\n",
    "    csdata = cs.CSData.csdata_from_arrow(\n",
    "        arrow_dataset=arrow_ds,\n",
    "        vocabulary=vocab,\n",
    "        save_dir=f'./tmp_c2s_{tag}',\n",
    "        save_name='data',\n",
    "        dataset_backend='arrow',\n",
    "    )\n",
    "    preds = predict_cell_types_of_data(\n",
    "        csdata=csdata,\n",
    "        csmodel=csmodel_in,\n",
    "        n_genes=TOP_K_GENES,\n",
    "        max_num_tokens=32,\n",
    "    )\n",
    "    return pd.DataFrame({\n",
    "        'cell_id': adata_in.obs_names.astype(str),\n",
    "        'y_true' : adata_in.obs['cell_type'].astype(str).values,\n",
    "        'y_pred' : [str(p).strip() for p in preds],\n",
    "        'version': tag,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = run_c2s(adata_original, 'original', csmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-masked",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_masked = run_c2s(adata_masked, 'masked', csmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-reconstructed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reconstructed = run_c2s(adata_reconstructed, 'reconstructed', csmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section7",
   "metadata": {},
   "source": [
    "## 7 · 3-Tier Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = str(text).strip().rstrip('.').lower()\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def classify(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    2 = Exactly correct  (normalized match)\n",
    "    1 = Partly correct   (substring containment OR Jaccard word overlap ≥ 30%)\n",
    "    0 = Not correct\n",
    "    \"\"\"\n",
    "    t, p = normalize(y_true), normalize(y_pred)\n",
    "    if t == p:\n",
    "        return 2\n",
    "    if p in t or t in p:\n",
    "        return 1\n",
    "    t_w = {w for w in re.findall(r'\\b\\w+\\b', t) if len(w) > 2}\n",
    "    p_w = {w for w in re.findall(r'\\b\\w+\\b', p) if len(w) > 2}\n",
    "    if t_w and p_w and len(t_w & p_w) / len(t_w | p_w) >= 0.30:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "label_map = {2: 'Exactly correct', 1: 'Partly correct', 0: 'Not correct'}\n",
    "\n",
    "def score_df(df):\n",
    "    df = df.copy()\n",
    "    df['score']   = df.apply(lambda r: classify(r['y_true'], r['y_pred']), axis=1)\n",
    "    df['verdict'] = df['score'].map(label_map)\n",
    "    return df\n",
    "\n",
    "df_original     = score_df(df_original)\n",
    "df_masked       = score_df(df_masked)\n",
    "df_reconstructed = score_df(df_reconstructed)\n",
    "\n",
    "print('Scoring complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(df, name):\n",
    "    n = len(df)\n",
    "    rows = []\n",
    "    for s in [2, 1, 0]:\n",
    "        cnt = (df['score'] == s).sum()\n",
    "        rows.append({'Version': name, 'Tier': label_map[s],\n",
    "                     'Count': cnt, 'Pct': cnt / n * 100})\n",
    "    return rows\n",
    "\n",
    "rows = []\n",
    "for df, name in [(df_original, 'Original (clean)'),\n",
    "                 (df_masked,   f'Masked ({int(MASK_FRACTION*100)}% zeroed)'),\n",
    "                 (df_reconstructed, 'Reconstructed (scGPT)')]:\n",
    "    rows.extend(summary(df, name))\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "\n",
    "print('=' * 65)\n",
    "print('  3-TIER ACCURACY COMPARISON')\n",
    "print('=' * 65)\n",
    "for name, grp in summary_df.groupby('Version', sort=False):\n",
    "    print(f'\\n  {name}')\n",
    "    for _, row in grp.iterrows():\n",
    "        bar = '█' * int(row['Pct'] / 5)\n",
    "        print(f'    {row[\"Tier\"]:<20}: {row[\"Count\"]:>2}/{N_CELLS}  ({row[\"Pct\"]:>5.1f}%)  {bar}')\n",
    "print('=' * 65)\n",
    "\n",
    "# Combined metric: Exact + Partial\n",
    "print('\\n  Exact + Partial (score ≥ 1):')\n",
    "for df, name in [(df_original, 'Original (clean)'),\n",
    "                 (df_masked,   f'Masked ({int(MASK_FRACTION*100)}% zeroed)'),\n",
    "                 (df_reconstructed, 'Reconstructed (scGPT)')]:\n",
    "    ep = (df['score'] >= 1).sum()\n",
    "    print(f'    {name:<30}: {ep}/{N_CELLS}  ({ep/N_CELLS*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-per-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Per-cell side-by-side view ────────────────────────────────────────────────\n",
    "compare = df_original[['cell_id', 'y_true']].copy()\n",
    "compare['pred_original']     = df_original['y_pred']\n",
    "compare['score_original']    = df_original['score']\n",
    "compare['pred_masked']       = df_masked['y_pred']\n",
    "compare['score_masked']      = df_masked['score']\n",
    "compare['pred_reconstructed']  = df_reconstructed['y_pred']\n",
    "compare['score_reconstructed'] = df_reconstructed['score']\n",
    "compare['scgpt_helped'] = compare['score_reconstructed'] > compare['score_masked']\n",
    "compare['scgpt_hurt']   = compare['score_reconstructed'] < compare['score_masked']\n",
    "\n",
    "print(f'scGPT improved prediction: {compare[\"scgpt_helped\"].sum()} cells')\n",
    "print(f'scGPT hurt prediction    : {compare[\"scgpt_hurt\"].sum()} cells')\n",
    "print(f'No change                : {(~compare[\"scgpt_helped\"] & ~compare[\"scgpt_hurt\"]).sum()} cells')\n",
    "\n",
    "pd.set_option('display.max_colwidth', 55)\n",
    "compare[['y_true',\n",
    "         'pred_masked', 'score_masked',\n",
    "         'pred_reconstructed', 'score_reconstructed',\n",
    "         'scgpt_helped']].style.apply(\n",
    "    lambda col: ['background-color: #c8e6c9' if v else\n",
    "                 'background-color: #ffcdd2' if col.name == 'scgpt_hurt' else ''\n",
    "                 for v in col], subset=['scgpt_helped']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Save full results ─────────────────────────────────────────────────────────\n",
    "out = Path('./scgpt_reconstruction_results.csv')\n",
    "compare.to_csv(out, index=False)\n",
    "print('Saved:', out.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c2s_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
