{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# scGPT Gene Masking → Reconstruction → C2S Cell-Type Evaluation\n",
    "\n",
    "**Pipeline:**\n",
    "1. Load 24 donor cells (same sample as `c2s_donor_celltype_prediction.ipynb`)\n",
    "2. **Mask** – randomly zero out `MASK_FRACTION` of each cell's expressed genes\n",
    "3. **Reconstruct** – feed masked cells through `tdc/scGPT` (with `-1` mask tokens)\n",
    "   and replace masked positions with scGPT's predicted expression values\n",
    "4. **Evaluate** – run C2S cell-type prediction on three AnnData objects:\n",
    "   - `original` (clean baseline)\n",
    "   - `masked`   (corrupted, masked genes → 0)\n",
    "   - `reconstructed` (scGPT-repaired)\n",
    "5. **Compare** results side-by-side using the 3-tier accuracy metric\n",
    "   (Exactly correct / Partly correct / Not correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# No extra installs needed – everything required is already in the environment.\n",
    "# (torch, numpy, scanpy, anndata, cell2sentence, transformers, tqdm)\n",
    "print('Environment ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cell-imports2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import torch\n",
    "\n",
    "import cell2sentence as cs\n",
    "from cell2sentence.tasks import predict_cell_types_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cell-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ── Configuration ─────────────────────────────────────────────────────────────\n",
    "SEED          = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "H5AD_PATH     = Path('../../data/dominguez_conde_immune_tissue_two_donors.h5ad')\n",
    "DONOR_COLUMN  = 'batch_condition'\n",
    "DONOR_VALUE   = 'A29'\n",
    "N_CELLS       = 24\n",
    "TOP_K_GENES   = 200          # genes passed to C2S\n",
    "MASK_FRACTION = 0.40         # fraction of expressed genes to mask per cell\n",
    "# MASK_VALUE and PAD_VALUE come from the model's args.json (loaded later):\n",
    "#   mask_value = -1  (sentinel for positions to reconstruct)\n",
    "#   pad_value  = -2  (padding, distinct from mask)\n",
    "C2S_MODEL     = 'vandijklab/C2S-Pythia-410m-cell-type-prediction'\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', DEVICE)\n",
    "\n",
    "assert H5AD_PATH.exists(), f'File not found: {H5AD_PATH.resolve()}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section1",
   "metadata": {},
   "source": [
    "## 1 · Load data & sample 24 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cell-load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (29773, 36503)\n",
      "Donor A29: 17327 cells  →  sampled 24\n",
      "cell_type\n",
      "macrophage                                               4\n",
      "memory B cell                                            3\n",
      "naive thymus-derived CD4-positive, alpha-beta T cell     3\n",
      "T follicular helper cell                                 2\n",
      "classical monocyte                                       2\n",
      "plasma cell                                              2\n",
      "CD4-positive helper T cell                               1\n",
      "CD16-negative, CD56-bright natural killer cell, human    1\n",
      "alveolar macrophage                                      1\n",
      "effector memory CD4-positive, alpha-beta T cell          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "adata = ad.read_h5ad(H5AD_PATH)\n",
    "print('Full dataset shape:', adata.shape)\n",
    "\n",
    "adata_donor = adata[adata.obs[DONOR_COLUMN] == DONOR_VALUE].copy()\n",
    "rng = np.random.default_rng(SEED)\n",
    "idx = rng.choice(adata_donor.n_obs, size=N_CELLS, replace=False)\n",
    "adata_small = adata_donor[idx].copy()\n",
    "\n",
    "print(f'Donor {DONOR_VALUE}: {adata_donor.n_obs} cells  →  sampled {adata_small.n_obs}')\n",
    "print(adata_small.obs['cell_type'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section2",
   "metadata": {},
   "source": [
    "## 2 · Preprocessing (normalize + log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cell-preprocess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression matrix: (24, 36503)\n",
      "Sparsity: 95.3% zeros per cell on average\n"
     ]
    }
   ],
   "source": [
    "adata_small.var_names_make_unique()\n",
    "sc.pp.normalize_total(adata_small, target_sum=1e4)\n",
    "sc.pp.log1p(adata_small)\n",
    "\n",
    "# Dense expression matrix  (n_cells × n_genes)\n",
    "import scipy.sparse as sp\n",
    "X_orig = adata_small.X.toarray() if sp.issparse(adata_small.X) else adata_small.X.copy()\n",
    "gene_names = np.array(adata_small.var_names.tolist())\n",
    "\n",
    "print('Expression matrix:', X_orig.shape)\n",
    "print(f'Sparsity: {(X_orig == 0).mean()*100:.1f}% zeros per cell on average')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section3",
   "metadata": {},
   "source": [
    "## 3 · Random gene masking\n",
    "\n",
    "For each cell, `MASK_FRACTION` of the expressed (non-zero) genes are set to  \n",
    "`MASK_VALUE = -1` internally. A separate zero-copy is created for C2S  \n",
    "(since C2S expects non-negative expression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cell-mask",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked 16337 genes across 24 cells (~681 per cell, 40% of expressed)\n"
     ]
    }
   ],
   "source": [
    "# X_scgpt_in : expression matrix sent to scGPT  (masked genes = -1, kept in tokenizer)\n",
    "# X_masked   : expression matrix for C2S masked baseline  (masked genes = 0)\n",
    "# mask_record: list of boolean arrays tracking which gene positions were masked\n",
    "\n",
    "rng_mask = np.random.default_rng(SEED)\n",
    "\n",
    "X_scgpt_in = X_orig.copy()\n",
    "X_masked   = X_orig.copy()\n",
    "mask_record = []          # mask_record[i] -> indices of masked genes in cell i\n",
    "\n",
    "total_masked = 0\n",
    "for i in range(X_orig.shape[0]):\n",
    "    expressed_idx = np.where(X_orig[i] > 0)[0]\n",
    "    n_mask = max(1, int(len(expressed_idx) * MASK_FRACTION))\n",
    "    masked_idx = rng_mask.choice(expressed_idx, size=n_mask, replace=False)\n",
    "\n",
    "    X_scgpt_in[i, masked_idx] = MASK_VALUE  # -1  → tokenizer keeps these\n",
    "    X_masked[i, masked_idx]   = 0.0         # 0   → removed from C2S\n",
    "\n",
    "    mask_record.append(masked_idx)\n",
    "    total_masked += n_mask\n",
    "\n",
    "print(f'Masked {total_masked} genes across {N_CELLS} cells'\n",
    "      f' (~{total_masked/N_CELLS:.0f} per cell, {MASK_FRACTION*100:.0f}% of expressed)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "lzx4qzn2b7r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout masking — 16337 genes masked across 24 cells\n",
      "  Top-20 (marker) genes masked:  1.7%  ← should be LOW\n",
      "  Bot-20 (noise) genes masked:   0.0%  ← should be HIGH\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ── Section: Dropout-weighted masking ─────────────────────────────────────────\n",
    "# In real scRNA-seq, low-expression genes are preferentially lost due to technical\n",
    "# dropout (Poisson noise, capture efficiency). Uniform random masking (above) treats\n",
    "# all genes equally — unrealistic. Here we weight by inverse rank so that lowly\n",
    "# expressed genes are masked more often, mimicking true dropout patterns.\n",
    "# MASK_FRACTION remains the same; only which genes are masked changes.\n",
    "\n",
    "from scipy.stats import rankdata as _rankdata\n",
    "\n",
    "rng_drop = np.random.default_rng(SEED + 1)   # different seed → different masked positions\n",
    "\n",
    "X_scgpt_drop_in = X_orig.copy()\n",
    "X_drop_masked   = X_orig.copy()\n",
    "mask_record_drop = []\n",
    "\n",
    "total_masked_drop = 0\n",
    "for i in range(X_orig.shape[0]):\n",
    "    expressed_idx = np.where(X_orig[i] > 0)[0]\n",
    "    expr_vals     = X_orig[i, expressed_idx].astype(float)\n",
    "\n",
    "    # Inverse-rank weights: low expression → high mask probability\n",
    "    ranks     = _rankdata(expr_vals, method='average')   # 1 = lowest, N = highest\n",
    "    inv_ranks = (ranks.max() - ranks + 1)                # invert: low expr → high weight\n",
    "    probs     = inv_ranks / inv_ranks.sum()\n",
    "\n",
    "    n_mask     = max(1, int(len(expressed_idx) * MASK_FRACTION))\n",
    "    masked_idx = rng_drop.choice(expressed_idx, size=n_mask, replace=False, p=probs)\n",
    "\n",
    "    X_scgpt_drop_in[i, masked_idx] = MASK_VALUE   # -1 sentinel for scGPT\n",
    "    X_drop_masked[i, masked_idx]   = 0.0           # 0 for C2S masked baseline\n",
    "    mask_record_drop.append(masked_idx)\n",
    "    total_masked_drop += n_mask\n",
    "\n",
    "# ── Sanity check: verify high-expression genes are rarely masked ──────────────\n",
    "top20_rate = np.mean([\n",
    "    np.isin(np.argsort(X_orig[i])[-20:], mask_record_drop[i]).mean()\n",
    "    for i in range(N_CELLS)\n",
    "])\n",
    "bot20_rate = np.mean([\n",
    "    np.isin(np.argsort(X_orig[i])[:20], mask_record_drop[i]).mean()\n",
    "    for i in range(N_CELLS)\n",
    "])\n",
    "print(f'Dropout masking — {total_masked_drop} genes masked across {N_CELLS} cells')\n",
    "print(f'  Top-20 (marker) genes masked:  {top20_rate:.1%}  ← should be LOW')\n",
    "print(f'  Bot-20 (noise) genes masked:   {bot20_rate:.1%}  ← should be HIGH')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section4",
   "metadata": {},
   "source": [
    "\n",
    "## 4 · scGPT reconstruction  *(no TDC – native scgpt package)*\n",
    "\n",
    "We load the model via `huggingface_hub.snapshot_download` and the native\n",
    "`scgpt.model.TransformerModel` + `scgpt.tokenizer.GeneVocab`.\n",
    "\n",
    "**Masking strategy:** masked genes are set to `-1` (scGPT's standard mask sentinel).\n",
    "Since `-1 ≠ 0`, they stay in the gene sequence passed to the model.  \n",
    "`mlm_output` predicts expression at **every position** – including the `-1` ones.  \n",
    "Those predicted values replace the masked genes in `X_reconstructed`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cell-scgpt-load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel + GeneVocab defined (no scgpt library used).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ── scGPT model – self-contained PyTorch implementation ───────────────────────\n",
    "# Adapted from https://github.com/bowang-lab/scGPT (MIT License).\n",
    "# No scgpt library required – only torch + huggingface_hub.\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Mapping, Optional, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "\n",
    "# ── GeneVocab: replaces scgpt.tokenizer.GeneVocab ────────────────────────────\n",
    "class GeneVocab:\n",
    "    \"\"\"Minimal gene-name ↔ token-ID vocabulary loaded from vocab.json.\"\"\"\n",
    "\n",
    "    def __init__(self, gene_to_id: dict):\n",
    "        self._g2i = gene_to_id\n",
    "        self._i2g = {v: k for k, v in gene_to_id.items()}\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path):\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        # Format A: {\"gene_name\": int_id, ...}\n",
    "        if isinstance(data, dict) and all(isinstance(v, int) for v in data.values()):\n",
    "            return cls(data)\n",
    "        # Format B: torchtext-style {\"itos\": [...], ...}\n",
    "        if isinstance(data, dict) and \"itos\" in data:\n",
    "            return cls({t: i for i, t in enumerate(data[\"itos\"])})\n",
    "        # Format C: list of tokens\n",
    "        if isinstance(data, list):\n",
    "            return cls({t: i for i, t in enumerate(data)})\n",
    "        raise ValueError(f\"Cannot parse vocab format in {path}\")\n",
    "\n",
    "    def __contains__(self, gene):  return gene in self._g2i\n",
    "    def __getitem__(self, gene):   return self._g2i[gene]\n",
    "    def __len__(self):             return len(self._g2i)\n",
    "\n",
    "\n",
    "# ── Sub-modules ───────────────────────────────────────────────────────────────\n",
    "class GeneEncoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, padding_idx=None):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)\n",
    "        self.enc_norm  = nn.LayerNorm(embedding_dim)\n",
    "    def forward(self, x):\n",
    "        return self.enc_norm(self.embedding(x))\n",
    "\n",
    "\n",
    "class ContinuousValueEncoder(nn.Module):\n",
    "    \"\"\"Projects scalar expression values → d_model embedding.\"\"\"\n",
    "    def __init__(self, d_model, dropout=0.1, max_value=512):\n",
    "        super().__init__()\n",
    "        self.max_value = max_value\n",
    "        self.linear1   = nn.Linear(1, d_model)\n",
    "        self.linear2   = nn.Linear(d_model, d_model)\n",
    "        self.norm      = nn.LayerNorm(d_model)\n",
    "        self.dropout   = nn.Dropout(dropout)\n",
    "    def forward(self, x):                          # x: (B, L)\n",
    "        x = x.unsqueeze(-1).clamp(-self.max_value, self.max_value)\n",
    "        x = self.linear1(x).relu()\n",
    "        return self.dropout(self.norm(self.linear2(x)))\n",
    "\n",
    "\n",
    "class CategoryValueEncoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, padding_idx=None):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)\n",
    "        self.enc_norm  = nn.LayerNorm(embedding_dim)\n",
    "    def forward(self, x):\n",
    "        return self.enc_norm(self.embedding(x.long()))\n",
    "\n",
    "\n",
    "class ExprDecoder(nn.Module):\n",
    "    \"\"\"MLP that predicts scalar expression from transformer hidden states.\"\"\"\n",
    "    def __init__(self, d_model, explicit_zero_prob=False, use_batch_labels=False):\n",
    "        super().__init__()\n",
    "        d_in = d_model * 2 if use_batch_labels else d_model\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_in, d_model), nn.LeakyReLU(),\n",
    "            nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "        self.explicit_zero_prob = explicit_zero_prob\n",
    "        if explicit_zero_prob:\n",
    "            self.zero_logit = nn.Sequential(\n",
    "                nn.Linear(d_in, d_model), nn.LeakyReLU(),\n",
    "                nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
    "                nn.Linear(d_model, 1),\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        pred = self.fc(x).squeeze(-1)           # (B, L)\n",
    "        out  = {\"pred\": pred}\n",
    "        if self.explicit_zero_prob:\n",
    "            out[\"zero_probs\"] = torch.sigmoid(self.zero_logit(x).squeeze(-1))\n",
    "        return out\n",
    "\n",
    "\n",
    "class ClsDecoder(nn.Module):\n",
    "    def __init__(self, d_model, n_cls, nlayers=3, activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(nlayers - 1):\n",
    "            layers += [nn.Linear(d_model, d_model), activation(), nn.LayerNorm(d_model)]\n",
    "        layers.append(nn.Linear(d_model, n_cls))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class MVCDecoder(nn.Module):\n",
    "    \"\"\"Masked-value-consistency decoder (inner-product style).\"\"\"\n",
    "    def __init__(self, d_model, arch_style=\"inner product\", query_activation=nn.Sigmoid,\n",
    "                 hidden_activation=nn.PReLU, explicit_zero_prob=False, use_batch_labels=False):\n",
    "        super().__init__()\n",
    "        self.arch_style        = arch_style\n",
    "        self.explicit_zero_prob = explicit_zero_prob\n",
    "        self.gene2query        = nn.Linear(d_model, d_model)\n",
    "        self.query_activation  = query_activation()\n",
    "        self.W                 = nn.Linear(d_model, d_model, bias=False)\n",
    "        if explicit_zero_prob:\n",
    "            self.fc_zero = nn.Linear(d_model, 1)\n",
    "    def forward(self, cell_emb, gene_embs):\n",
    "        query     = self.query_activation(self.gene2query(gene_embs))  # (B, L, d)\n",
    "        cell_emb_ = self.W(cell_emb).unsqueeze(2)                      # (B, d, 1)\n",
    "        pred      = torch.bmm(query, cell_emb_).squeeze(2)             # (B, L)\n",
    "        out = {\"mvc_output\": pred}\n",
    "        if self.explicit_zero_prob:\n",
    "            out[\"mvc_zero_probs\"] = torch.sigmoid(self.fc_zero(gene_embs).squeeze(-1))\n",
    "        return out\n",
    "\n",
    "\n",
    "class AdversarialDiscriminator(nn.Module):\n",
    "    def __init__(self, d_model, n_cls, nlayers=3, activation=nn.LeakyReLU, reverse_grad=False):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(nlayers - 1):\n",
    "            layers += [nn.Linear(d_model, d_model), activation(), nn.LayerNorm(d_model)]\n",
    "        layers.append(nn.Linear(d_model, n_cls))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# ── TransformerModel ──────────────────────────────────────────────────────────\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    scGPT TransformerModel – self-contained PyTorch reimplementation.\n",
    "    Weights are fully compatible with the original scgpt library checkpoint.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ntoken: int, d_model: int, nhead: int, d_hid: int, nlayers: int,\n",
    "        nlayers_cls: int = 3, n_cls: int = 1, vocab=None,\n",
    "        dropout: float = 0.5, pad_token: str = \"<pad>\", pad_value: int = 0,\n",
    "        do_mvc: bool = False, do_dab: bool = False,\n",
    "        use_batch_labels: bool = False, num_batch_labels: Optional[int] = None,\n",
    "        domain_spec_batchnorm: bool = False,\n",
    "        input_emb_style: str = \"continuous\", n_input_bins: Optional[int] = None,\n",
    "        cell_emb_style: str = \"cls\", mvc_decoder_style: str = \"inner product\",\n",
    "        ecs_threshold: float = 0.3, explicit_zero_prob: bool = False,\n",
    "        use_fast_transformer: bool = False,   # ignored – always use standard attn\n",
    "        fast_transformer_backend: str = \"flash\",\n",
    "        pre_norm: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model             = d_model\n",
    "        self.do_mvc              = do_mvc\n",
    "        self.do_dab              = do_dab\n",
    "        self.use_batch_labels    = use_batch_labels\n",
    "        self.cell_emb_style      = cell_emb_style\n",
    "        self.explicit_zero_prob  = explicit_zero_prob\n",
    "        self.pad_value           = pad_value\n",
    "        self.ecs_threshold       = ecs_threshold\n",
    "\n",
    "        pad_idx = vocab[pad_token] if (vocab is not None and pad_token in vocab) else pad_value\n",
    "\n",
    "        # Embeddings\n",
    "        self.encoder       = GeneEncoder(ntoken, d_model, padding_idx=pad_idx)\n",
    "        if input_emb_style == \"continuous\":\n",
    "            self.value_encoder = ContinuousValueEncoder(d_model, dropout)\n",
    "        elif input_emb_style == \"category\":\n",
    "            self.value_encoder = CategoryValueEncoder(n_input_bins, d_model, padding_idx=0)\n",
    "        else:\n",
    "            self.value_encoder = nn.Identity()\n",
    "\n",
    "        if use_batch_labels:\n",
    "            self.batch_encoder = nn.Embedding(num_batch_labels, d_model)\n",
    "\n",
    "        # Batch-norm (domain_spec_batchnorm not needed; stub keeps weight keys intact)\n",
    "        self.bn = nn.BatchNorm1d(d_model)\n",
    "        if domain_spec_batchnorm:\n",
    "            self.dsbn = nn.BatchNorm1d(d_model)   # stub\n",
    "\n",
    "        # Transformer\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_hid,\n",
    "            dropout=dropout, batch_first=True, norm_first=pre_norm,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(enc_layer, num_layers=nlayers)\n",
    "\n",
    "        # Decoders\n",
    "        self.decoder     = ExprDecoder(d_model, explicit_zero_prob, use_batch_labels)\n",
    "        self.cls_decoder = ClsDecoder(d_model, n_cls, nlayers=nlayers_cls)\n",
    "        if do_mvc:\n",
    "            self.mvc_decoder = MVCDecoder(d_model, mvc_decoder_style, explicit_zero_prob=explicit_zero_prob,\n",
    "                                          use_batch_labels=use_batch_labels)\n",
    "        if do_dab:\n",
    "            self.grad_reverse_discriminator = AdversarialDiscriminator(d_model, n_cls=num_batch_labels,\n",
    "                                                                        reverse_grad=True)\n",
    "        self.sim = nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "        nn.init.uniform_(self.encoder.embedding.weight, -0.1, 0.1)\n",
    "\n",
    "    def _encode(self, src, values, src_key_padding_mask, batch_labels=None):\n",
    "        src_emb = self.encoder(src)           # (B, L, d)\n",
    "        val_emb = self.value_encoder(values)  # (B, L, d)\n",
    "        emb     = src_emb + val_emb\n",
    "\n",
    "        if self.use_batch_labels and batch_labels is not None:\n",
    "            emb = emb + self.batch_encoder(batch_labels).unsqueeze(1)\n",
    "\n",
    "        B, L, d = emb.shape\n",
    "        emb = self.bn(emb.view(B * L, d)).view(B, L, d)\n",
    "\n",
    "        return self.transformer_encoder(emb, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def _cell_emb(self, layer_out, values=None):\n",
    "        if self.cell_emb_style == \"cls\":\n",
    "            return layer_out[:, 0, :]\n",
    "        non_pad = (values != self.pad_value).float().unsqueeze(-1) if values is not None \\\n",
    "                  else torch.ones(*layer_out.shape[:2], 1, device=layer_out.device)\n",
    "        return (layer_out * non_pad).sum(1) / non_pad.sum(1).clamp(min=1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: Tensor, values: Tensor, src_key_padding_mask: Tensor,\n",
    "        batch_labels: Optional[Tensor] = None,\n",
    "        CLS: bool = False, CCE: bool = False, MVC: bool = False,\n",
    "        ECS: bool = False, do_sample: bool = False,\n",
    "    ) -> Mapping[str, Tensor]:\n",
    "        h      = self._encode(src, values, src_key_padding_mask, batch_labels)\n",
    "        output = {}\n",
    "\n",
    "        mlm = self.decoder(h)\n",
    "        output[\"mlm_output\"] = mlm[\"pred\"]               # (B, L)  ← used for reconstruction\n",
    "        if self.explicit_zero_prob and \"zero_probs\" in mlm:\n",
    "            output[\"mlm_zero_probs\"] = mlm[\"zero_probs\"]\n",
    "\n",
    "        cell_emb           = self._cell_emb(h, values)\n",
    "        output[\"cell_emb\"] = cell_emb\n",
    "\n",
    "        if CLS:\n",
    "            output[\"cls_output\"] = self.cls_decoder(cell_emb)\n",
    "        if MVC and self.do_mvc:\n",
    "            output.update(self.mvc_decoder(cell_emb, h))\n",
    "        if self.do_dab:\n",
    "            output[\"dab_output\"] = self.grad_reverse_discriminator(cell_emb)\n",
    "        return output\n",
    "\n",
    "\n",
    "print('TransformerModel + GeneVocab defined (no scgpt library used).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2mliwd1j9m8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local checkpoint: C:\\Users\\Daniel\\Desktop\\GitProjects\\Improving-Cell2Sentence-with-Single-Cell-Foundation-Model-Embeddings\\models\\scGPT\n",
      "Files: ['args.json', 'best_model.pt', 'vocab.json']\n",
      "Vocab size: 60697  PAD_ID=60694  UNK_ID=60694\n",
      "pad_value=-2  mask_value=-1  n_bins=51\n",
      "input_style=binned  fast_transformer=True\n",
      "Remapped 24 flash-attn weight keys → standard PyTorch names\n",
      "Weights loaded — missing: 14, unexpected: 1\n",
      "  Missing : ['bn.weight', 'bn.bias', 'bn.running_mean', 'bn.running_var', 'cls_decoder.fc.0.weight', 'cls_decoder.fc.0.bias', 'cls_decoder.fc.2.weight', 'cls_decoder.fc.2.bias', 'cls_decoder.fc.3.weight', 'cls_decoder.fc.3.bias']\n",
      "  Unexpected: ['flag_encoder.weight']\n",
      "\n",
      "scGPT ready on cpu.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ── Load model from local checkpoint ─────────────────────────────────────────\n",
    "SCGPT_DIR = Path('../../models/scGPT')\n",
    "assert SCGPT_DIR.exists(), f'Model folder not found: {SCGPT_DIR.resolve()}'\n",
    "print('Using local checkpoint:', SCGPT_DIR.resolve())\n",
    "print('Files:', sorted(f.name for f in SCGPT_DIR.iterdir()))\n",
    "\n",
    "# ── Vocab ─────────────────────────────────────────────────────────────────────\n",
    "vocab = GeneVocab.from_file(str(SCGPT_DIR / 'vocab.json'))\n",
    "PAD_ID = vocab['<pad>'] if '<pad>' in vocab else 0\n",
    "UNK_ID = vocab['<unk>'] if '<unk>' in vocab else PAD_ID\n",
    "print(f'Vocab size: {len(vocab)}  PAD_ID={PAD_ID}  UNK_ID={UNK_ID}')\n",
    "\n",
    "# ── Config (args.json) ────────────────────────────────────────────────────────\n",
    "with open(SCGPT_DIR / 'args.json') as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Key values read from args.json:\n",
    "#   embsize=512, nheads=8, d_hid=512, nlayers=12, n_layers_cls=3\n",
    "#   input_emb_style=\"continuous\", pad_value=-2, mask_value=-1, MVC=True\n",
    "#   fast_transformer=True  ← trained with flash-attn (Wqkv naming)\n",
    "#   input_style=\"binned\", n_bins=51  ← expects bin indices 0-50, not log1p floats\n",
    "PAD_VALUE  = cfg.get('pad_value',  -2)   # -2 in this checkpoint\n",
    "MASK_VALUE = cfg.get('mask_value', -1)   # -1 (confirms our masking strategy)\n",
    "N_BINS     = cfg.get('n_bins', 51)       # 51 bins for expression discretization\n",
    "print(f'pad_value={PAD_VALUE}  mask_value={MASK_VALUE}  n_bins={N_BINS}')\n",
    "print(f'input_style={cfg.get(\"input_style\")}  fast_transformer={cfg.get(\"fast_transformer\")}')\n",
    "\n",
    "# ── Build architecture ────────────────────────────────────────────────────────\n",
    "scgpt_model = TransformerModel(\n",
    "    ntoken           = len(vocab),\n",
    "    d_model          = cfg['embsize'],\n",
    "    nhead            = cfg['nheads'],\n",
    "    d_hid            = cfg['d_hid'],\n",
    "    nlayers          = cfg['nlayers'],\n",
    "    nlayers_cls      = cfg.get('n_layers_cls', cfg.get('nlayers_cls', 3)),\n",
    "    n_cls            = 1,\n",
    "    vocab            = vocab,\n",
    "    dropout          = 0.0,                  # no dropout at inference\n",
    "    pad_token        = cfg.get('pad_token', '<pad>'),\n",
    "    pad_value        = PAD_VALUE,\n",
    "    do_mvc           = cfg.get('MVC', False),\n",
    "    do_dab           = cfg.get('do_dab', False),\n",
    "    use_batch_labels = cfg.get('use_batch_labels', False),\n",
    "    num_batch_labels = cfg.get('num_batch_labels', 1),\n",
    "    domain_spec_batchnorm = cfg.get('dsbn', False),\n",
    "    input_emb_style  = cfg.get('input_emb_style', 'continuous'),\n",
    "    n_input_bins     = cfg.get('n_bins', 51),\n",
    "    cell_emb_style   = 'cls' if not cfg.get('no_cls', True) else 'avg-non-pad',\n",
    "    explicit_zero_prob = cfg.get('explicit_zero_prob', False),\n",
    "    use_fast_transformer = False,           # disable flash-attn (CPU / Windows)\n",
    "    pre_norm         = cfg.get('pre_norm', False),\n",
    ")\n",
    "\n",
    "# ── Load weights ──────────────────────────────────────────────────────────────\n",
    "ckpt_path = SCGPT_DIR / 'best_model.pt'\n",
    "state = torch.load(str(ckpt_path), map_location='cpu', weights_only=False)\n",
    "if isinstance(state, dict) and 'model_state_dict' in state:\n",
    "    state = state['model_state_dict']\n",
    "\n",
    "# ── Remap Flash-Attention weights → standard PyTorch MultiheadAttention ───────\n",
    "# The checkpoint was trained with fast_transformer=True (flash-attn library).\n",
    "# Flash-attn fuses Q/K/V into a single 'Wqkv' matrix; standard PyTorch uses\n",
    "# 'in_proj_weight'. We also remap feed-forward layers if named 'mlp.fc*'.\n",
    "n_remapped = 0\n",
    "for li in range(cfg['nlayers']):\n",
    "    pfx = f\"transformer_encoder.layers.{li}.self_attn.\"\n",
    "\n",
    "    # Q/K/V projection: Wqkv.weight (3*d, d) → in_proj_weight\n",
    "    if pfx + \"Wqkv.weight\" in state:\n",
    "        state[pfx + \"in_proj_weight\"] = state.pop(pfx + \"Wqkv.weight\")\n",
    "        state[pfx + \"in_proj_bias\"]   = state.pop(pfx + \"Wqkv.bias\")\n",
    "        n_remapped += 2\n",
    "\n",
    "    # Feed-forward layers: mlp.fc1 → linear1, mlp.fc2 → linear2\n",
    "    ffn_pfx = f\"transformer_encoder.layers.{li}.\"\n",
    "    for old, new in [(\"mlp.fc1\", \"linear1\"), (\"mlp.fc2\", \"linear2\")]:\n",
    "        for suffix in [\".weight\", \".bias\"]:\n",
    "            old_key = ffn_pfx + old + suffix\n",
    "            new_key = ffn_pfx + new + suffix\n",
    "            if old_key in state:\n",
    "                state[new_key] = state.pop(old_key)\n",
    "                n_remapped += 1\n",
    "\n",
    "print(f'Remapped {n_remapped} flash-attn weight keys → standard PyTorch names')\n",
    "\n",
    "missing, unexpected = scgpt_model.load_state_dict(state, strict=False)\n",
    "print(f'Weights loaded — missing: {len(missing)}, unexpected: {len(unexpected)}')\n",
    "if missing:\n",
    "    print('  Missing :', missing[:10])\n",
    "if unexpected:\n",
    "    print('  Unexpected:', unexpected[:10])\n",
    "# After remap: expect missing ≈ 4 (only bn.* batch-norm stats), unexpected ≈ 0\n",
    "\n",
    "scgpt_model = scgpt_model.to(DEVICE).eval()\n",
    "print(f'\\nscGPT ready on {DEVICE}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-scgpt-reconstruct",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scGPT reconstruction:  54%|█████▍    | 13/24 [00:33<00:26,  2.38s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "\n",
    "def bin_expression_cell(expr_vals, n_bins=51):\n",
    "    \"\"\"\n",
    "    Convert a log1p-normalized expression vector into scGPT bin indices.\n",
    "\n",
    "    The model was trained with input_style='binned', n_bins=51:\n",
    "      - 0         → zero / unexpressed\n",
    "      - 1 .. n_bins-1 → rank-based bins for expressed genes (1 = lowest, n_bins-1 = highest)\n",
    "\n",
    "    Masked positions (value == -1) are passed through unchanged.\n",
    "    \"\"\"\n",
    "    binned = np.zeros_like(expr_vals, dtype=np.float32)\n",
    "    nz_mask = expr_vals > 0\n",
    "    nz_vals = expr_vals[nz_mask]\n",
    "    if len(nz_vals) == 0:\n",
    "        return binned\n",
    "    # rank-based equal-frequency binning → [1, n_bins-1]\n",
    "    ranks = rankdata(nz_vals, method='min').astype(np.float32)\n",
    "    binned[nz_mask] = np.floor(ranks / ranks.max() * (n_bins - 2)).astype(np.float32) + 1\n",
    "    return binned\n",
    "\n",
    "\n",
    "def gene_names_to_ids(names):\n",
    "    \"\"\"Map gene name strings → scGPT vocabulary IDs (UNK_ID for out-of-vocab genes).\"\"\"\n",
    "    return np.array([vocab[g] if g in vocab else UNK_ID for g in names], dtype=np.int64)\n",
    "\n",
    "\n",
    "# X_reconstructed: copy of original; masked gene positions will be overwritten\n",
    "X_reconstructed = X_orig.copy()\n",
    "n_in_vocab  = 0\n",
    "n_recovered = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(N_CELLS), desc='scGPT reconstruction'):\n",
    "\n",
    "        cell_expr = X_scgpt_in[i]          # shape (n_genes,); -1 for masked genes\n",
    "\n",
    "        # ── Select non-zero genes (includes -1 masked ones) ──────────────────\n",
    "        nonzero_idx = np.where(cell_expr != 0)[0]\n",
    "        if len(nonzero_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        genes_sel  = gene_names[nonzero_idx]                    # gene name strings\n",
    "        vals_sel   = cell_expr[nonzero_idx].astype(np.float32)  # expr values (incl. -1)\n",
    "        gene_ids   = gene_names_to_ids(genes_sel)               # vocab IDs\n",
    "\n",
    "        # ── Bin the original (non-masked) expression values ───────────────────\n",
    "        # The model was trained with binned inputs (0–50), not log1p floats.\n",
    "        # We compute bins on the original cell expression to get the right scale.\n",
    "        orig_vals_sel  = X_orig[i, nonzero_idx].astype(np.float32)\n",
    "        vals_binned    = bin_expression_cell(orig_vals_sel, n_bins=N_BINS)\n",
    "        # Restore the MASK_VALUE sentinel (-1) for masked positions\n",
    "        vals_binned[vals_sel < 0] = float(MASK_VALUE)   # -1 → stays as mask sentinel\n",
    "\n",
    "        # ── Build tensors ─────────────────────────────────────────────────────\n",
    "        src_t   = torch.from_numpy(gene_ids).unsqueeze(0).to(DEVICE)        # (1, L)\n",
    "        vals_t  = torch.from_numpy(vals_binned).unsqueeze(0).to(DEVICE)     # (1, L)\n",
    "        pad_mask = torch.zeros(1, len(gene_ids), dtype=torch.bool, device=DEVICE)\n",
    "\n",
    "        n_in_vocab += int((gene_ids != UNK_ID).sum())\n",
    "\n",
    "        # ── scGPT forward pass ────────────────────────────────────────────────\n",
    "        out = scgpt_model(\n",
    "            src                  = src_t,\n",
    "            values               = vals_t,\n",
    "            src_key_padding_mask = pad_mask,\n",
    "            CLS                  = False,\n",
    "        )\n",
    "\n",
    "        mlm = out.get('mlm_output')\n",
    "        if mlm is None:\n",
    "            print(f'  Cell {i}: mlm_output not in scGPT output '\n",
    "                  f'(keys: {list(out.keys())}) – skipping')\n",
    "            continue\n",
    "\n",
    "        if mlm.ndim == 3:\n",
    "            mlm = mlm.squeeze(-1)\n",
    "        mlm_np = mlm.squeeze(0).cpu().float().numpy()   # (L,)\n",
    "\n",
    "        # ── Find masked positions and convert bin predictions → log1p scale ───\n",
    "        masked_in_local = np.where(vals_sel < 0)[0]    # positions where value was -1\n",
    "        if len(masked_in_local) == 0:\n",
    "            continue\n",
    "\n",
    "        masked_orig_idx = nonzero_idx[masked_in_local]\n",
    "\n",
    "        # scGPT predicts bin indices (0–50). Convert back to the log1p scale of\n",
    "        # this cell so that X_reconstructed stays on a consistent scale with the\n",
    "        # un-masked positions (which still hold log1p values from X_orig).\n",
    "        #   bin 0 → 0.0  (unexpressed)\n",
    "        #   bin N_BINS-1 → max expressed log1p value in this cell\n",
    "        predicted_bins  = np.clip(mlm_np[masked_in_local], 0.0, N_BINS - 1)\n",
    "        cell_max_log1p  = float(X_orig[i].max()) or 1.0   # avoid /0\n",
    "        predicted_log1p = predicted_bins / (N_BINS - 1) * cell_max_log1p\n",
    "\n",
    "        X_reconstructed[i, masked_orig_idx] = predicted_log1p\n",
    "        n_recovered += len(masked_orig_idx)\n",
    "\n",
    "print(f'\\nReconstruction complete.')\n",
    "print(f'  Avg genes in scGPT vocab / cell : {n_in_vocab / N_CELLS:.0f}')\n",
    "print(f'  Masked genes recovered          : {n_recovered} / {total_masked}'\n",
    "      f'  ({n_recovered / total_masked * 100:.1f} %)')\n",
    "reconstructed_nz = (X_reconstructed > 0).mean()\n",
    "print(f'  X_reconstructed non-zero fraction: {reconstructed_nz:.3f}'\n",
    "      f'  (original was {(X_orig > 0).mean():.3f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nmq3yj3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ── scGPT reconstruction on DROPOUT-WEIGHTED masked cells ─────────────────────\n",
    "# Same logic as the uniform reconstruction above; only the input matrix differs.\n",
    "# Reuses bin_expression_cell() and gene_names_to_ids() from the cell above.\n",
    "\n",
    "X_drop_reconstructed = X_orig.copy()\n",
    "n_drop_in_vocab  = 0\n",
    "n_drop_recovered = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(N_CELLS), desc='scGPT reconstruction (dropout mask)'):\n",
    "        cell_expr   = X_scgpt_drop_in[i]\n",
    "        nonzero_idx = np.where(cell_expr != 0)[0]\n",
    "        if len(nonzero_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        genes_sel = gene_names[nonzero_idx]\n",
    "        vals_sel  = cell_expr[nonzero_idx].astype(np.float32)\n",
    "        gene_ids  = gene_names_to_ids(genes_sel)\n",
    "\n",
    "        orig_vals_sel = X_orig[i, nonzero_idx].astype(np.float32)\n",
    "        vals_binned   = bin_expression_cell(orig_vals_sel, n_bins=N_BINS)\n",
    "        vals_binned[vals_sel < 0] = float(MASK_VALUE)\n",
    "\n",
    "        src_t    = torch.from_numpy(gene_ids).unsqueeze(0).to(DEVICE)\n",
    "        vals_t   = torch.from_numpy(vals_binned).unsqueeze(0).to(DEVICE)\n",
    "        pad_mask = torch.zeros(1, len(gene_ids), dtype=torch.bool, device=DEVICE)\n",
    "\n",
    "        n_drop_in_vocab += int((gene_ids != UNK_ID).sum())\n",
    "\n",
    "        out = scgpt_model(src=src_t, values=vals_t, src_key_padding_mask=pad_mask, CLS=False)\n",
    "        mlm = out.get('mlm_output')\n",
    "        if mlm is None:\n",
    "            continue\n",
    "        if mlm.ndim == 3:\n",
    "            mlm = mlm.squeeze(-1)\n",
    "        mlm_np = mlm.squeeze(0).cpu().float().numpy()\n",
    "\n",
    "        masked_in_local = np.where(vals_sel < 0)[0]\n",
    "        if len(masked_in_local) == 0:\n",
    "            continue\n",
    "\n",
    "        masked_orig_idx = nonzero_idx[masked_in_local]\n",
    "        predicted_bins  = np.clip(mlm_np[masked_in_local], 0.0, N_BINS - 1)\n",
    "        cell_max_log1p  = float(X_orig[i].max()) or 1.0\n",
    "        predicted_log1p = predicted_bins / (N_BINS - 1) * cell_max_log1p\n",
    "\n",
    "        X_drop_reconstructed[i, masked_orig_idx] = predicted_log1p\n",
    "        n_drop_recovered += len(masked_orig_idx)\n",
    "\n",
    "print(f'Dropout reconstruction complete.')\n",
    "print(f'  Recovered {n_drop_recovered} / {total_masked_drop} genes  ({n_drop_recovered/total_masked_drop*100:.1f}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lpbc1pe763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ── Direct reconstruction quality metrics (both masking variants) ─────────────\n",
    "# Measure how well scGPT recovered masked values before involving C2S.\n",
    "# Compares predicted expression at masked positions to the true (original) values.\n",
    "\n",
    "def direct_recon_quality(X_recon, X_true, mask_records, label):\n",
    "    corrs, mses = [], []\n",
    "    for i in range(N_CELLS):\n",
    "        idx       = mask_records[i]\n",
    "        true_vals = X_true[i, idx]\n",
    "        pred_vals = X_recon[i, idx]\n",
    "        if len(true_vals) > 1 and true_vals.std() > 0 and pred_vals.std() > 0:\n",
    "            r = np.corrcoef(true_vals, pred_vals)[0, 1]\n",
    "            if not np.isnan(r):\n",
    "                corrs.append(r)\n",
    "        mses.append(float(((true_vals - pred_vals) ** 2).mean()))\n",
    "    print(f'{label}')\n",
    "    print(f'  Mean Pearson r (expression correlation) : {np.nanmean(corrs):.3f}')\n",
    "    print(f'  Mean MSE (log1p scale)                  : {np.nanmean(mses):.4f}')\n",
    "    return float(np.nanmean(corrs))\n",
    "\n",
    "\n",
    "def top_k_overlap(Xa, Xb, k=TOP_K_GENES):\n",
    "    \"\"\"Fraction of top-K expressed genes shared between Xa and Xb per cell.\"\"\"\n",
    "    return float(np.mean([\n",
    "        len(set(np.argsort(Xa[i])[-k:]) & set(np.argsort(Xb[i])[-k:])) / k\n",
    "        for i in range(Xa.shape[0])\n",
    "    ]))\n",
    "\n",
    "\n",
    "print('── Direct reconstruction quality (masked positions only) ──')\n",
    "direct_recon_quality(X_reconstructed,      X_orig, mask_record,      'Uniform mask   → scGPT recon:')\n",
    "direct_recon_quality(X_drop_reconstructed, X_orig, mask_record_drop, 'Dropout mask   → scGPT recon:')\n",
    "\n",
    "print(f'\\n── Top-{TOP_K_GENES} gene overlap with original ──')\n",
    "print(f'  Uniform masked          : {top_k_overlap(X_masked,           X_orig):.3f}')\n",
    "print(f'  Uniform reconstructed   : {top_k_overlap(X_reconstructed,    X_orig):.3f}')\n",
    "print(f'  Dropout masked          : {top_k_overlap(X_drop_masked,      X_orig):.3f}')\n",
    "print(f'  Dropout reconstructed   : {top_k_overlap(X_drop_reconstructed, X_orig):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section5",
   "metadata": {},
   "source": [
    "## 5 · Build three AnnData objects\n",
    "\n",
    "| Name | Expression matrix | Description |\n",
    "|---|---|---|\n",
    "| `adata_original` | `X_orig` | Clean, unmodified cells |\n",
    "| `adata_masked` | `X_masked` | Corrupted: `MASK_FRACTION` genes zeroed |\n",
    "| `adata_reconstructed` | `X_reconstructed` | scGPT-repaired: masked genes filled with predicted expression |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-build-adatas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData objects created:\n",
      "  original         non-zero fraction: 0.047\n",
      "  masked           non-zero fraction: 0.028\n",
      "  reconstructed    non-zero fraction: 0.047\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "def make_adata(X_new, template_adata):\n",
    "    \"\"\"Clone the obs/var metadata from template and replace the expression matrix.\"\"\"\n",
    "    a = ad.AnnData(\n",
    "        X=sp.csr_matrix(X_new),\n",
    "        obs=template_adata.obs.copy(),\n",
    "        var=template_adata.var.copy(),\n",
    "    )\n",
    "    return a\n",
    "\n",
    "adata_original     = make_adata(X_orig,         adata_small)\n",
    "adata_masked       = make_adata(X_masked,        adata_small)\n",
    "adata_reconstructed = make_adata(X_reconstructed, adata_small)\n",
    "\n",
    "print('AnnData objects created:')\n",
    "for name, a in [('original', adata_original), ('masked', adata_masked), ('reconstructed', adata_reconstructed)]:\n",
    "    mean_nonzero = (a.X.toarray() > 0).mean()\n",
    "    print(f'  {name:15s}  non-zero fraction: {mean_nonzero:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p7ggrl58x1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ── AnnData objects for dropout-masking variant ───────────────────────────────\n",
    "adata_drop_masked        = make_adata(X_drop_masked,        adata_small)\n",
    "adata_drop_reconstructed = make_adata(X_drop_reconstructed, adata_small)\n",
    "\n",
    "print('Dropout AnnData objects created:')\n",
    "for name, a in [('drop_masked', adata_drop_masked), ('drop_reconstructed', adata_drop_reconstructed)]:\n",
    "    mean_nonzero = (a.X.toarray() > 0).mean()\n",
    "    print(f'  {name:<20}  non-zero fraction: {mean_nonzero:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section6",
   "metadata": {},
   "source": [
    "## 6 · C2S Cell-Type Prediction (3×)\n",
    "\n",
    "> **Runtime note:** each C2S call takes ~9 min on CPU (22 s/cell × 24 cells).  \n",
    "> Total ≈ 27 min. Grab a coffee ☕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-c2s-helpers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "C2S model loaded: vandijklab/C2S-Pythia-410m-cell-type-prediction\n"
     ]
    }
   ],
   "source": [
    "label_cols = [c for c in ['cell_type', DONOR_COLUMN, 'tissue', 'sex', 'organism']\n",
    "              if c in adata_small.obs.columns]\n",
    "\n",
    "# Load C2S model once (we'll reuse it across all three predictions)\n",
    "csmodel = cs.CSModel(\n",
    "    model_name_or_path=C2S_MODEL,\n",
    "    save_dir='./tmp_c2s_reconstruction_model',\n",
    "    save_name='pretrained_c2s_inference',\n",
    ")\n",
    "print('C2S model loaded:', C2S_MODEL)\n",
    "\n",
    "\n",
    "def run_c2s(adata_in, tag, csmodel_in):\n",
    "    \"\"\"Run C2S cell-type prediction and return a DataFrame with y_true / y_pred.\"\"\"\n",
    "    print(f'\\n─── C2S: {tag} ───')\n",
    "    arrow_ds, vocab = cs.CSData.adata_to_arrow(\n",
    "        adata_in,\n",
    "        random_state=SEED,\n",
    "        sentence_delimiter=' ',\n",
    "        label_col_names=label_cols,\n",
    "    )\n",
    "    csdata = cs.CSData.csdata_from_arrow(\n",
    "        arrow_dataset=arrow_ds,\n",
    "        vocabulary=vocab,\n",
    "        save_dir=f'./tmp_c2s_{tag}',\n",
    "        save_name='data',\n",
    "        dataset_backend='arrow',\n",
    "    )\n",
    "    preds = predict_cell_types_of_data(\n",
    "        csdata=csdata,\n",
    "        csmodel=csmodel_in,\n",
    "        n_genes=TOP_K_GENES,\n",
    "        max_num_tokens=32,\n",
    "    )\n",
    "    return pd.DataFrame({\n",
    "        'cell_id': adata_in.obs_names.astype(str),\n",
    "        'y_true' : adata_in.obs['cell_type'].astype(str).values,\n",
    "        'y_pred' : [str(p).strip() for p in preds],\n",
    "        'version': tag,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "─── C2S: original ───\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN: more variables (36503) than observations (24)... did you mean to transpose the object (e.g. adata.T)?\n",
      "WARN: more variables (36503) than observations (24), did you mean to transpose the object (e.g. adata.T)?\n",
      "100%|██████████| 24/24 [00:00<00:00, 721.32it/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 24/24 [00:00<00:00, 2190.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model from path on disk: ./tmp_c2s_reconstruction_model\\pretrained_c2s_inference\n",
      "Predicting cell types for 24 cells using CSModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [09:11<00:00, 22.97s/it]\n"
     ]
    }
   ],
   "source": [
    "df_original = run_c2s(adata_original, 'original', csmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-masked",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN: more variables (36503) than observations (24)... did you mean to transpose the object (e.g. adata.T)?\n",
      "WARN: more variables (36503) than observations (24), did you mean to transpose the object (e.g. adata.T)?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "─── C2S: masked ───\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 850.47it/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 24/24 [00:00<00:00, 2191.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model from path on disk: ./tmp_c2s_reconstruction_model\\pretrained_c2s_inference\n",
      "Predicting cell types for 24 cells using CSModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [09:11<00:00, 22.97s/it]\n"
     ]
    }
   ],
   "source": [
    "df_masked = run_c2s(adata_masked, 'masked', csmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-reconstructed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN: more variables (36503) than observations (24)... did you mean to transpose the object (e.g. adata.T)?\n",
      "WARN: more variables (36503) than observations (24), did you mean to transpose the object (e.g. adata.T)?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "─── C2S: reconstructed ───\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 730.96it/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 24/24 [00:00<00:00, 1960.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model from path on disk: ./tmp_c2s_reconstruction_model\\pretrained_c2s_inference\n",
      "Predicting cell types for 24 cells using CSModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [08:42<00:00, 21.76s/it]\n"
     ]
    }
   ],
   "source": [
    "df_reconstructed = run_c2s(adata_reconstructed, 'reconstructed', csmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z44wxzzlbnl",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_masked = run_c2s(adata_drop_masked, 'drop_masked', csmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2t5azf5dkw7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_reconstructed = run_c2s(adata_drop_reconstructed, 'drop_reconstructed', csmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-section7",
   "metadata": {},
   "source": [
    "## 7 · 3-Tier Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-evaluate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring complete.\n"
     ]
    }
   ],
   "source": [
    "def normalize(text):\n",
    "    text = str(text).strip().rstrip('.').lower()\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def classify(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    2 = Exactly correct  (normalized match)\n",
    "    1 = Partly correct   (substring containment OR Jaccard word overlap ≥ 30%)\n",
    "    0 = Not correct\n",
    "    \"\"\"\n",
    "    t, p = normalize(y_true), normalize(y_pred)\n",
    "    if t == p:\n",
    "        return 2\n",
    "    if p in t or t in p:\n",
    "        return 1\n",
    "    t_w = {w for w in re.findall(r'\\b\\w+\\b', t) if len(w) > 2}\n",
    "    p_w = {w for w in re.findall(r'\\b\\w+\\b', p) if len(w) > 2}\n",
    "    if t_w and p_w and len(t_w & p_w) / len(t_w | p_w) >= 0.30:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "label_map = {2: 'Exactly correct', 1: 'Partly correct', 0: 'Not correct'}\n",
    "\n",
    "def score_df(df):\n",
    "    df = df.copy()\n",
    "    df['score']   = df.apply(lambda r: classify(r['y_true'], r['y_pred']), axis=1)\n",
    "    df['verdict'] = df['score'].map(label_map)\n",
    "    return df\n",
    "\n",
    "df_original     = score_df(df_original)\n",
    "df_masked       = score_df(df_masked)\n",
    "df_reconstructed = score_df(df_reconstructed)\n",
    "\n",
    "print('Scoring complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "  3-TIER ACCURACY COMPARISON\n",
      "=================================================================\n",
      "\n",
      "  Original (clean)\n",
      "    Exactly correct     :  4/24  ( 16.7%)  ███\n",
      "    Partly correct      : 13/24  ( 54.2%)  ██████████\n",
      "    Not correct         :  7/24  ( 29.2%)  █████\n",
      "\n",
      "  Masked (40% zeroed)\n",
      "    Exactly correct     :  8/24  ( 33.3%)  ██████\n",
      "    Partly correct      : 13/24  ( 54.2%)  ██████████\n",
      "    Not correct         :  3/24  ( 12.5%)  ██\n",
      "\n",
      "  Reconstructed (scGPT)\n",
      "    Exactly correct     :  5/24  ( 20.8%)  ████\n",
      "    Partly correct      : 14/24  ( 58.3%)  ███████████\n",
      "    Not correct         :  5/24  ( 20.8%)  ████\n",
      "=================================================================\n",
      "\n",
      "  Exact + Partial (score ≥ 1):\n",
      "    Original (clean)              : 17/24  (70.8%)\n",
      "    Masked (40% zeroed)           : 21/24  (87.5%)\n",
      "    Reconstructed (scGPT)         : 19/24  (79.2%)\n"
     ]
    }
   ],
   "source": [
    "def summary(df, name):\n",
    "    n = len(df)\n",
    "    rows = []\n",
    "    for s in [2, 1, 0]:\n",
    "        cnt = (df['score'] == s).sum()\n",
    "        rows.append({'Version': name, 'Tier': label_map[s],\n",
    "                     'Count': cnt, 'Pct': cnt / n * 100})\n",
    "    return rows\n",
    "\n",
    "rows = []\n",
    "for df, name in [(df_original, 'Original (clean)'),\n",
    "                 (df_masked,   f'Masked ({int(MASK_FRACTION*100)}% zeroed)'),\n",
    "                 (df_reconstructed, 'Reconstructed (scGPT)')]:\n",
    "    rows.extend(summary(df, name))\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "\n",
    "print('=' * 65)\n",
    "print('  3-TIER ACCURACY COMPARISON')\n",
    "print('=' * 65)\n",
    "for name, grp in summary_df.groupby('Version', sort=False):\n",
    "    print(f'\\n  {name}')\n",
    "    for _, row in grp.iterrows():\n",
    "        bar = '█' * int(row['Pct'] / 5)\n",
    "        print(f'    {row[\"Tier\"]:<20}: {row[\"Count\"]:>2}/{N_CELLS}  ({row[\"Pct\"]:>5.1f}%)  {bar}')\n",
    "print('=' * 65)\n",
    "\n",
    "# Combined metric: Exact + Partial\n",
    "print('\\n  Exact + Partial (score ≥ 1):')\n",
    "for df, name in [(df_original, 'Original (clean)'),\n",
    "                 (df_masked,   f'Masked ({int(MASK_FRACTION*100)}% zeroed)'),\n",
    "                 (df_reconstructed, 'Reconstructed (scGPT)')]:\n",
    "    ep = (df['score'] >= 1).sum()\n",
    "    print(f'    {name:<30}: {ep}/{N_CELLS}  ({ep/N_CELLS*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-per-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT improved prediction: 5 cells\n",
      "scGPT hurt prediction    : 8 cells\n",
      "No change                : 11 cells\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5b0ac_row1_col5, #T_5b0ac_row13_col5, #T_5b0ac_row16_col5, #T_5b0ac_row18_col5, #T_5b0ac_row19_col5 {\n",
       "  background-color: #c8e6c9;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5b0ac\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5b0ac_level0_col0\" class=\"col_heading level0 col0\" >y_true</th>\n",
       "      <th id=\"T_5b0ac_level0_col1\" class=\"col_heading level0 col1\" >pred_masked</th>\n",
       "      <th id=\"T_5b0ac_level0_col2\" class=\"col_heading level0 col2\" >score_masked</th>\n",
       "      <th id=\"T_5b0ac_level0_col3\" class=\"col_heading level0 col3\" >pred_reconstructed</th>\n",
       "      <th id=\"T_5b0ac_level0_col4\" class=\"col_heading level0 col4\" >score_reconstructed</th>\n",
       "      <th id=\"T_5b0ac_level0_col5\" class=\"col_heading level0 col5\" >scgpt_helped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5b0ac_row0_col0\" class=\"data row0 col0\" >mast cell</td>\n",
       "      <td id=\"T_5b0ac_row0_col1\" class=\"data row0 col1\" >mast cell.</td>\n",
       "      <td id=\"T_5b0ac_row0_col2\" class=\"data row0 col2\" >2</td>\n",
       "      <td id=\"T_5b0ac_row0_col3\" class=\"data row0 col3\" >mast cell.</td>\n",
       "      <td id=\"T_5b0ac_row0_col4\" class=\"data row0 col4\" >2</td>\n",
       "      <td id=\"T_5b0ac_row0_col5\" class=\"data row0 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5b0ac_row1_col0\" class=\"data row1 col0\" >T follicular helper cell</td>\n",
       "      <td id=\"T_5b0ac_row1_col1\" class=\"data row1 col1\" >CD4-positive, alpha-beta T cell.</td>\n",
       "      <td id=\"T_5b0ac_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_5b0ac_row1_col3\" class=\"data row1 col3\" >CD4-positive helper T cell.</td>\n",
       "      <td id=\"T_5b0ac_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row1_col5\" class=\"data row1 col5\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5b0ac_row2_col0\" class=\"data row2 col0\" >plasma cell</td>\n",
       "      <td id=\"T_5b0ac_row2_col1\" class=\"data row2 col1\" >plasma cell.</td>\n",
       "      <td id=\"T_5b0ac_row2_col2\" class=\"data row2 col2\" >2</td>\n",
       "      <td id=\"T_5b0ac_row2_col3\" class=\"data row2 col3\" >B cell.</td>\n",
       "      <td id=\"T_5b0ac_row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row2_col5\" class=\"data row2 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5b0ac_row3_col0\" class=\"data row3 col0\" >plasma cell</td>\n",
       "      <td id=\"T_5b0ac_row3_col1\" class=\"data row3 col1\" >plasma cell.</td>\n",
       "      <td id=\"T_5b0ac_row3_col2\" class=\"data row3 col2\" >2</td>\n",
       "      <td id=\"T_5b0ac_row3_col3\" class=\"data row3 col3\" >naive B cell.</td>\n",
       "      <td id=\"T_5b0ac_row3_col4\" class=\"data row3 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row3_col5\" class=\"data row3 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5b0ac_row4_col0\" class=\"data row4 col0\" >effector memory CD4-positive, alpha-beta T cell</td>\n",
       "      <td id=\"T_5b0ac_row4_col1\" class=\"data row4 col1\" >naive thymus-derived CD4-positive, alpha-beta T cell.</td>\n",
       "      <td id=\"T_5b0ac_row4_col2\" class=\"data row4 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row4_col3\" class=\"data row4 col3\" >naive thymus-derived CD4-positive, alpha-beta T cell.</td>\n",
       "      <td id=\"T_5b0ac_row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row4_col5\" class=\"data row4 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5b0ac_row5_col0\" class=\"data row5 col0\" >naive thymus-derived CD4-positive, alpha-beta T cell</td>\n",
       "      <td id=\"T_5b0ac_row5_col1\" class=\"data row5 col1\" >CD4-positive, alpha-beta memory T cell.</td>\n",
       "      <td id=\"T_5b0ac_row5_col2\" class=\"data row5 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row5_col3\" class=\"data row5 col3\" >T cell.</td>\n",
       "      <td id=\"T_5b0ac_row5_col4\" class=\"data row5 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row5_col5\" class=\"data row5 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5b0ac_row6_col0\" class=\"data row6 col0\" >macrophage</td>\n",
       "      <td id=\"T_5b0ac_row6_col1\" class=\"data row6 col1\" >macrophage.</td>\n",
       "      <td id=\"T_5b0ac_row6_col2\" class=\"data row6 col2\" >2</td>\n",
       "      <td id=\"T_5b0ac_row6_col3\" class=\"data row6 col3\" >monocyte.</td>\n",
       "      <td id=\"T_5b0ac_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_5b0ac_row6_col5\" class=\"data row6 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5b0ac_row7_col0\" class=\"data row7 col0\" >memory B cell</td>\n",
       "      <td id=\"T_5b0ac_row7_col1\" class=\"data row7 col1\" >naive B cell.</td>\n",
       "      <td id=\"T_5b0ac_row7_col2\" class=\"data row7 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row7_col3\" class=\"data row7 col3\" >B cell.</td>\n",
       "      <td id=\"T_5b0ac_row7_col4\" class=\"data row7 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row7_col5\" class=\"data row7 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5b0ac_row8_col0\" class=\"data row8 col0\" >memory B cell</td>\n",
       "      <td id=\"T_5b0ac_row8_col1\" class=\"data row8 col1\" >B cell.</td>\n",
       "      <td id=\"T_5b0ac_row8_col2\" class=\"data row8 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row8_col3\" class=\"data row8 col3\" >naive B cell.</td>\n",
       "      <td id=\"T_5b0ac_row8_col4\" class=\"data row8 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row8_col5\" class=\"data row8 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5b0ac_row9_col0\" class=\"data row9 col0\" >erythroid lineage cell</td>\n",
       "      <td id=\"T_5b0ac_row9_col1\" class=\"data row9 col1\" >erythroid progenitor cell.</td>\n",
       "      <td id=\"T_5b0ac_row9_col2\" class=\"data row9 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row9_col3\" class=\"data row9 col3\" >germ cell.</td>\n",
       "      <td id=\"T_5b0ac_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_5b0ac_row9_col5\" class=\"data row9 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_5b0ac_row10_col0\" class=\"data row10 col0\" >alveolar macrophage</td>\n",
       "      <td id=\"T_5b0ac_row10_col1\" class=\"data row10 col1\" >macrophage.</td>\n",
       "      <td id=\"T_5b0ac_row10_col2\" class=\"data row10 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row10_col3\" class=\"data row10 col3\" >macrophage.</td>\n",
       "      <td id=\"T_5b0ac_row10_col4\" class=\"data row10 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row10_col5\" class=\"data row10 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_5b0ac_row11_col0\" class=\"data row11 col0\" >CD16-negative, CD56-bright natural killer cell, human</td>\n",
       "      <td id=\"T_5b0ac_row11_col1\" class=\"data row11 col1\" >CD8-positive, alpha-beta memory T cell.</td>\n",
       "      <td id=\"T_5b0ac_row11_col2\" class=\"data row11 col2\" >0</td>\n",
       "      <td id=\"T_5b0ac_row11_col3\" class=\"data row11 col3\" >CD8-positive, alpha-beta memory T cell.</td>\n",
       "      <td id=\"T_5b0ac_row11_col4\" class=\"data row11 col4\" >0</td>\n",
       "      <td id=\"T_5b0ac_row11_col5\" class=\"data row11 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_5b0ac_row12_col0\" class=\"data row12 col0\" >classical monocyte</td>\n",
       "      <td id=\"T_5b0ac_row12_col1\" class=\"data row12 col1\" >classical monocyte.</td>\n",
       "      <td id=\"T_5b0ac_row12_col2\" class=\"data row12 col2\" >2</td>\n",
       "      <td id=\"T_5b0ac_row12_col3\" class=\"data row12 col3\" >monocyte.</td>\n",
       "      <td id=\"T_5b0ac_row12_col4\" class=\"data row12 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row12_col5\" class=\"data row12 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_5b0ac_row13_col0\" class=\"data row13 col0\" >classical monocyte</td>\n",
       "      <td id=\"T_5b0ac_row13_col1\" class=\"data row13 col1\" >monocyte.</td>\n",
       "      <td id=\"T_5b0ac_row13_col2\" class=\"data row13 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row13_col3\" class=\"data row13 col3\" >classical monocyte.</td>\n",
       "      <td id=\"T_5b0ac_row13_col4\" class=\"data row13 col4\" >2</td>\n",
       "      <td id=\"T_5b0ac_row13_col5\" class=\"data row13 col5\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_5b0ac_row14_col0\" class=\"data row14 col0\" >naive thymus-derived CD4-positive, alpha-beta T cell</td>\n",
       "      <td id=\"T_5b0ac_row14_col1\" class=\"data row14 col1\" >naive thymus-derived CD4-positive, alpha-beta T cell.</td>\n",
       "      <td id=\"T_5b0ac_row14_col2\" class=\"data row14 col2\" >2</td>\n",
       "      <td id=\"T_5b0ac_row14_col3\" class=\"data row14 col3\" >CD4-positive, alpha-beta memory T cell.</td>\n",
       "      <td id=\"T_5b0ac_row14_col4\" class=\"data row14 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row14_col5\" class=\"data row14 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_5b0ac_row15_col0\" class=\"data row15 col0\" >effector memory CD8-positive, alpha-beta T cell, terminally differentiated</td>\n",
       "      <td id=\"T_5b0ac_row15_col1\" class=\"data row15 col1\" >CD8-positive, alpha-beta memory T cell.</td>\n",
       "      <td id=\"T_5b0ac_row15_col2\" class=\"data row15 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row15_col3\" class=\"data row15 col3\" >CD8-positive, alpha-beta memory T cell.</td>\n",
       "      <td id=\"T_5b0ac_row15_col4\" class=\"data row15 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row15_col5\" class=\"data row15 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_5b0ac_row16_col0\" class=\"data row16 col0\" >CD4-positive helper T cell</td>\n",
       "      <td id=\"T_5b0ac_row16_col1\" class=\"data row16 col1\" >mature alpha-beta T cell.</td>\n",
       "      <td id=\"T_5b0ac_row16_col2\" class=\"data row16 col2\" >0</td>\n",
       "      <td id=\"T_5b0ac_row16_col3\" class=\"data row16 col3\" >CD4-positive, alpha-beta memory T cell.</td>\n",
       "      <td id=\"T_5b0ac_row16_col4\" class=\"data row16 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row16_col5\" class=\"data row16 col5\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_5b0ac_row17_col0\" class=\"data row17 col0\" >T follicular helper cell</td>\n",
       "      <td id=\"T_5b0ac_row17_col1\" class=\"data row17 col1\" >CD4-positive helper T cell.</td>\n",
       "      <td id=\"T_5b0ac_row17_col2\" class=\"data row17 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row17_col3\" class=\"data row17 col3\" >CD4-positive helper T cell.</td>\n",
       "      <td id=\"T_5b0ac_row17_col4\" class=\"data row17 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row17_col5\" class=\"data row17 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_5b0ac_row18_col0\" class=\"data row18 col0\" >naive thymus-derived CD4-positive, alpha-beta T cell</td>\n",
       "      <td id=\"T_5b0ac_row18_col1\" class=\"data row18 col1\" >CD4-positive, alpha-beta T cell.</td>\n",
       "      <td id=\"T_5b0ac_row18_col2\" class=\"data row18 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row18_col3\" class=\"data row18 col3\" >naive thymus-derived CD4-positive, alpha-beta T cell.</td>\n",
       "      <td id=\"T_5b0ac_row18_col4\" class=\"data row18 col4\" >2</td>\n",
       "      <td id=\"T_5b0ac_row18_col5\" class=\"data row18 col5\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_5b0ac_row19_col0\" class=\"data row19 col0\" >naive B cell</td>\n",
       "      <td id=\"T_5b0ac_row19_col1\" class=\"data row19 col1\" >B cell.</td>\n",
       "      <td id=\"T_5b0ac_row19_col2\" class=\"data row19 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row19_col3\" class=\"data row19 col3\" >naive B cell.</td>\n",
       "      <td id=\"T_5b0ac_row19_col4\" class=\"data row19 col4\" >2</td>\n",
       "      <td id=\"T_5b0ac_row19_col5\" class=\"data row19 col5\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_5b0ac_row20_col0\" class=\"data row20 col0\" >macrophage</td>\n",
       "      <td id=\"T_5b0ac_row20_col1\" class=\"data row20 col1\" >macrophage.</td>\n",
       "      <td id=\"T_5b0ac_row20_col2\" class=\"data row20 col2\" >2</td>\n",
       "      <td id=\"T_5b0ac_row20_col3\" class=\"data row20 col3\" >monocyte.</td>\n",
       "      <td id=\"T_5b0ac_row20_col4\" class=\"data row20 col4\" >0</td>\n",
       "      <td id=\"T_5b0ac_row20_col5\" class=\"data row20 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_5b0ac_row21_col0\" class=\"data row21 col0\" >macrophage</td>\n",
       "      <td id=\"T_5b0ac_row21_col1\" class=\"data row21 col1\" >elicited macrophage.</td>\n",
       "      <td id=\"T_5b0ac_row21_col2\" class=\"data row21 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row21_col3\" class=\"data row21 col3\" >monocyte.</td>\n",
       "      <td id=\"T_5b0ac_row21_col4\" class=\"data row21 col4\" >0</td>\n",
       "      <td id=\"T_5b0ac_row21_col5\" class=\"data row21 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_5b0ac_row22_col0\" class=\"data row22 col0\" >macrophage</td>\n",
       "      <td id=\"T_5b0ac_row22_col1\" class=\"data row22 col1\" >macrophage.</td>\n",
       "      <td id=\"T_5b0ac_row22_col2\" class=\"data row22 col2\" >2</td>\n",
       "      <td id=\"T_5b0ac_row22_col3\" class=\"data row22 col3\" >macrophage.</td>\n",
       "      <td id=\"T_5b0ac_row22_col4\" class=\"data row22 col4\" >2</td>\n",
       "      <td id=\"T_5b0ac_row22_col5\" class=\"data row22 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b0ac_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_5b0ac_row23_col0\" class=\"data row23 col0\" >memory B cell</td>\n",
       "      <td id=\"T_5b0ac_row23_col1\" class=\"data row23 col1\" >naive B cell.</td>\n",
       "      <td id=\"T_5b0ac_row23_col2\" class=\"data row23 col2\" >1</td>\n",
       "      <td id=\"T_5b0ac_row23_col3\" class=\"data row23 col3\" >naive B cell.</td>\n",
       "      <td id=\"T_5b0ac_row23_col4\" class=\"data row23 col4\" >1</td>\n",
       "      <td id=\"T_5b0ac_row23_col5\" class=\"data row23 col5\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26b453d4c50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── Per-cell side-by-side view ────────────────────────────────────────────────\n",
    "compare = df_original[['cell_id', 'y_true']].copy()\n",
    "compare['pred_original']     = df_original['y_pred']\n",
    "compare['score_original']    = df_original['score']\n",
    "compare['pred_masked']       = df_masked['y_pred']\n",
    "compare['score_masked']      = df_masked['score']\n",
    "compare['pred_reconstructed']  = df_reconstructed['y_pred']\n",
    "compare['score_reconstructed'] = df_reconstructed['score']\n",
    "compare['scgpt_helped'] = compare['score_reconstructed'] > compare['score_masked']\n",
    "compare['scgpt_hurt']   = compare['score_reconstructed'] < compare['score_masked']\n",
    "\n",
    "print(f'scGPT improved prediction: {compare[\"scgpt_helped\"].sum()} cells')\n",
    "print(f'scGPT hurt prediction    : {compare[\"scgpt_hurt\"].sum()} cells')\n",
    "print(f'No change                : {(~compare[\"scgpt_helped\"] & ~compare[\"scgpt_hurt\"]).sum()} cells')\n",
    "\n",
    "pd.set_option('display.max_colwidth', 55)\n",
    "compare[['y_true',\n",
    "         'pred_masked', 'score_masked',\n",
    "         'pred_reconstructed', 'score_reconstructed',\n",
    "         'scgpt_helped']].style.apply(\n",
    "    lambda col: ['background-color: #c8e6c9' if v else\n",
    "                 'background-color: #ffcdd2' if col.name == 'scgpt_hurt' else ''\n",
    "                 for v in col], subset=['scgpt_helped']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\Daniel\\Desktop\\GitProjects\\Improving-Cell2Sentence-with-Single-Cell-Foundation-Model-Embeddings\\notebooks\\c2s_donor_new_approach\\scgpt_reconstruction_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ── Save full results ─────────────────────────────────────────────────────────\n",
    "out = Path('./scgpt_reconstruction_results.csv')\n",
    "compare.to_csv(out, index=False)\n",
    "print('Saved:', out.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9myhmwvtms9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ── Score dropout-masking results + 5-way comparison ─────────────────────────\n",
    "df_drop_masked        = score_df(df_drop_masked)\n",
    "df_drop_reconstructed = score_df(df_drop_reconstructed)\n",
    "\n",
    "print('=' * 72)\n",
    "print('  5-WAY ACCURACY COMPARISON')\n",
    "print('  (Exact = full match, Partial = substring/Jaccard overlap)')\n",
    "print('=' * 72)\n",
    "for df, name in [\n",
    "    (df_original,          'Original (clean)'),\n",
    "    (df_masked,            f'Uniform masked ({int(MASK_FRACTION*100)}% random)'),\n",
    "    (df_reconstructed,     'Uniform reconstructed (scGPT)'),\n",
    "    (df_drop_masked,       f'Dropout masked ({int(MASK_FRACTION*100)}% weighted)'),\n",
    "    (df_drop_reconstructed,'Dropout reconstructed (scGPT)'),\n",
    "]:\n",
    "    ex = (df['score'] == 2).sum()\n",
    "    pa = (df['score'] == 1).sum()\n",
    "    no = (df['score'] == 0).sum()\n",
    "    ep = ex + pa\n",
    "    bar_ex = '█' * int(ex / N_CELLS * 20)\n",
    "    bar_ep = '█' * int(ep / N_CELLS * 20)\n",
    "    print(f'\\n  {name}')\n",
    "    print(f'    Exactly correct : {ex:>2}/{N_CELLS}  ({ex/N_CELLS*100:>5.1f}%)  {bar_ex}')\n",
    "    print(f'    Partly correct  : {pa:>2}/{N_CELLS}  ({pa/N_CELLS*100:>5.1f}%)')\n",
    "    print(f'    Not correct     : {no:>2}/{N_CELLS}  ({no/N_CELLS*100:>5.1f}%)')\n",
    "    print(f'    ─ Exact+Partial : {ep:>2}/{N_CELLS}  ({ep/N_CELLS*100:>5.1f}%)  {bar_ep}')\n",
    "print('=' * 72)\n",
    "\n",
    "# Save extended results\n",
    "compare_5way = df_original[['cell_id', 'y_true']].copy()\n",
    "compare_5way['pred_original']          = df_original['y_pred']\n",
    "compare_5way['score_original']         = df_original['score']\n",
    "compare_5way['pred_uniform_masked']    = df_masked['y_pred']\n",
    "compare_5way['score_uniform_masked']   = df_masked['score']\n",
    "compare_5way['pred_uniform_recon']     = df_reconstructed['y_pred']\n",
    "compare_5way['score_uniform_recon']    = df_reconstructed['score']\n",
    "compare_5way['pred_drop_masked']       = df_drop_masked['y_pred']\n",
    "compare_5way['score_drop_masked']      = df_drop_masked['score']\n",
    "compare_5way['pred_drop_recon']        = df_drop_reconstructed['y_pred']\n",
    "compare_5way['score_drop_recon']       = df_drop_reconstructed['score']\n",
    "\n",
    "out5 = Path('./scgpt_reconstruction_5way_results.csv')\n",
    "compare_5way.to_csv(out5, index=False)\n",
    "print(f'\\nSaved 5-way results: {out5.resolve()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c2s_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
